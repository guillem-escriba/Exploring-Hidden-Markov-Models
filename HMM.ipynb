{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pgmpy\n",
        "!gdown -q --id 1b2ryMxJOhAOhiPmphsS-0sJkJKuLJ9D4\n",
        "!gdown -q --id 19xqIcNf2WvcG3Hi95d4zv7CpMaJPriMe\n",
        "!gdown -q --id 1pD496PHFtTydlXqnY4s8JpFanP46bO0E\n",
        "!gdown -q --id 1kOSQm_PBSXR1rEr7-6xStUyfja3vXH3l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpEFtEuK3LXQ",
        "outputId": "8f6e8e95-d5ab-4bc2-9a17-3eb971143f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWEPYhPy3Jxh"
      },
      "source": [
        "# Inference in Hidden Markov Models\n",
        "\n",
        "\n",
        "In this lab session you will work with hidden Markov models (HMMs) using the [pgmpy library](http://www.pgmpy.org). By the end of the session you will be able to\n",
        "\n",
        "- Understand how to learn **hidden Markov models** from data\n",
        "- Implement the **belief propagation** to answer **filtering and prediction** queries\n",
        "- **Implement the Viterbi algorithm** for finding the most likely sequence of hidden states, given some evidence\n",
        "- Experiment with two tasks: a robot navigating on a grid, and how to improve a mispelled text\n",
        "\n",
        "This practice is inspired by https://www.cs.princeton.edu/courses/archive/fall12/cos402/assignments/programs/viterbi/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDSujyY-3Jxm"
      },
      "source": [
        "## The Hidden Markov Model\n",
        "\n",
        "A HMM is defined by a Markov chain over hidden variables $h_{1:T}=h_1,h_2,...,h_T$ and it is defined by\n",
        "- a probability distribution over the initial hidden state $p(h_1)$.\n",
        "- a state transition distribution $p(h_t|h_{t-1})$.\n",
        "\n",
        "Each hidden variable $h_t$ influences a corresponding visible variable $v_t$ through the observation model $p(v_t|h_t)$. The joint distribution can be written as\n",
        "$$p(v_{1:T},h_{1:T}) = p(h_1)p(v_1|h_1)\\prod_{t=2}^T p(h_{t}|h_{t-1})p(v_t|h_t).$$\n",
        "\n",
        "Let's define a class that encodes an HMM. This class will create the HMM with a predefined length ``n_vars``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfJ988Gu3Jxn"
      },
      "outputs": [],
      "source": [
        "from pgmpy.models import FactorGraph\n",
        "\n",
        "class HMM:\n",
        "    def __init__(self, n_vars, prior_fn, transition_fn, observation_fn, h_states, v_states, h_name='h', v_name='v'):\n",
        "        self.h = [f\"{h_name}{i}\" for i in range(n_vars)]\n",
        "        self.v = [f\"{v_name}{i}\" for i in range(n_vars)]\n",
        "        self.variables = self.h + self.v\n",
        "        self.state_names = dict([(h, h_states) for h in self.h] +\n",
        "                                [(v, v_states) for v in self.v])\n",
        "        self.f = self.create_factors(n_vars, prior_fn, transition_fn, observation_fn)\n",
        "        \n",
        "    def create_factors(self, n_vars, prior_fn, transition_fn, observation_fn):\n",
        "        \"\"\"\n",
        "        Given the amount of variables (n_vars) in the hidden markov model, it creates factors for\n",
        "        the prior of h_0, for all the transitions from h_{t-1} to h_t (for t in n_vars), and for\n",
        "        the observation function from h_t to v_t.\n",
        "        Returns a dict where keys are (tuples of) variables and values are factors.\n",
        "        E.g. {\"h_0\": DiscreteFactor,\n",
        "              (\"h_1\", \"h_2\"): DiscreteFactor,\n",
        "              (\"h_1\", \"v_1\"): DiscreteFactor,\n",
        "                           ...\n",
        "              }\n",
        "        \"\"\"\n",
        "        \n",
        "        factors = dict()      \n",
        "        for i in range(n_vars):\n",
        "            if i == 0:\n",
        "                # Prior factor\n",
        "                factors[self.h[i]] = prior_fn(self.h[i])\n",
        "            else:\n",
        "                # Transition factor\n",
        "                factors[(self.h[i-1], self.h[i])] = transition_fn(self.h[i-1], self.h[i])\n",
        "            # Observation factor\n",
        "            factors[(self.h[i], self.v[i])] = observation_fn(self.h[i], self.v[i])\n",
        "        return factors\n",
        "    \n",
        "    def to_factor_graph(self):\n",
        "        G = FactorGraph()\n",
        "        assert set(self.variables) == set(v for f in self.f.values() for v in f.variables)\n",
        "        G.add_nodes_from(self.variables)\n",
        "        G.add_factors(*self.f.values())\n",
        "        G.add_edges_from([(v, f) for f in self.f.values() for v in f.variables])\n",
        "        assert G.check_model()\n",
        "        return G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLy8NpJ83Jxq"
      },
      "source": [
        "## Basic setting\n",
        "\n",
        "Before tackling larger problems, and to be able to test our implementations, we will first consider a small version of our previous hidden Markov model of weather change over three days, where we can observe if an umbrella has been used or not. We define this factor graph next:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO6IuzSc3Jxr"
      },
      "outputs": [],
      "source": [
        "from pgmpy.factors.discrete import DiscreteFactor\n",
        "from pgmpy.models import FactorGraph\n",
        "\n",
        "weather_states = [\"sunny\", \"cloudy\", \"rainy\"]\n",
        "umbrella_states = [True, False]\n",
        "\n",
        "def day_prior(d):\n",
        "    return DiscreteFactor(variables=[d],\n",
        "                          cardinality=[3],\n",
        "                          values=[0.3, 0.4, 0.3],\n",
        "                          state_names={d: weather_states})\n",
        "\n",
        "def day_transition(d1, d2): # P(d2|d1)\n",
        "     return DiscreteFactor(variables=[d1, d2],\n",
        "                           cardinality=[3, 3],\n",
        "                           values=[0.7, 0.25, 0.05,\n",
        "                                   0.25, 0.35, 0.4,\n",
        "                                   0.25, 0.5, 0.25],\n",
        "                           state_names={d1: weather_states,\n",
        "                                        d2: weather_states})\n",
        "\n",
        "def take_umbrella_transition(d, u): # P(u|d)\n",
        "    return DiscreteFactor(variables=[d, u],\n",
        "                          cardinality=[3, 2],\n",
        "                          values=[0.2, 0.8,\n",
        "                                  0.6, 0.4,\n",
        "                                  0.95, 0.05],\n",
        "                          state_names={d: weather_states,\n",
        "                                       u: umbrella_states})\n",
        "\n",
        "# Expand the model for 3 days\n",
        "hmm_weather_3 = HMM(n_vars=3,\n",
        "                    prior_fn=day_prior,\n",
        "                    transition_fn=day_transition,\n",
        "                    observation_fn=take_umbrella_transition,\n",
        "                    h_states=weather_states,\n",
        "                    v_states=umbrella_states,\n",
        "                    h_name=\"w\",\n",
        "                    v_name=\"u\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQxgRQD-3Jxr"
      },
      "source": [
        "## Probabilistic Queries\n",
        "\n",
        "We will implement three types of queries:\n",
        "\n",
        "1. **Filtering** : the probability of the current hidden sate given a partial sequence of observations $p(h_t|v_{1:t})$.\n",
        "2. **Prediction** : the probability of a future hidden sate given a partial sequence of observations $p(h_s|v_{1:t})$, for a $s>t$.\n",
        "3. **Evidence** : the probability of a given a full sequence of observations $p(v_{1:T})$.\n",
        "4. **MAP state** : the most likely hidden trajectory given a full sequence of observations $p(v_{1:T})$.\n",
        "\n",
        "A naive way of computing the MAP of the hidden variables can be:\n",
        "1. Clamp the corresponding visible variables $v_{1:t}$.\n",
        "2. Run BP.\n",
        "3. Compute the joint probability of the corresponding hidden variables.\n",
        "3. Get the assignment with maximum probability.\n",
        "\n",
        "\n",
        "The following code calculates the joint hidden trajectory for the weather example with $T=3$ using belief propagation. Clearly, this approach will not scale to larger models. However, we will use it to check that our code is correct.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BELIEFPROPAGATION\n",
        "from functools import reduce\n",
        "import operator\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "\n",
        "def prod(iterable):\n",
        "    \n",
        "    \"\"\"\n",
        "      Returns the product of all the items in the iterable given in as input.\n",
        "    \"\"\"\n",
        "\n",
        "    return reduce(operator.mul, iterable, 1)\n",
        "\n",
        "class MyBeliefPropagation:\n",
        "    def __init__(self, factor_graph):\n",
        "        assert factor_graph.check_model()\n",
        "        self.original_graph = factor_graph\n",
        "        self.variables = factor_graph.get_variable_nodes()\n",
        "        \n",
        "        self.state_names = dict()\n",
        "        for f in self.original_graph.factors:\n",
        "            self.state_names.update(f.state_names)\n",
        "        self.bp_done = False\n",
        "\n",
        "    def factor_ones(self, v):\n",
        "        \"\"\"\n",
        "        Returns a DiscreteFactor for variable v with all ones.\n",
        "        \"\"\"\n",
        "        # IMPLEMENT\n",
        "        \n",
        "        return DiscreteFactor(variables=[v],\n",
        "                        cardinality=[len(self.state_names[v])],\n",
        "                        values=[1]*len(self.state_names[v]),\n",
        "                        state_names=self.state_names)\n",
        "        \n",
        "    def initialize_messages(self):\n",
        "        \"\"\"\n",
        "        This function creates, for each edge factor-variable, two messages: m(f->v) and \n",
        "        m(v->f). It initiliazies each message as a DiscreteFactor with all ones. It stores all\n",
        "        the messages in a dict of dict. Keys of both dicts are either factors or variables.\n",
        "        Messages are indexed as messages[to][from]. For example, m(x->y) is in messages[y][x].\n",
        "        It's done this way because it will be useful to get all messages that go to a variable\n",
        "        or a factor.\n",
        "        \"\"\"\n",
        "        self.messages = defaultdict(dict)\n",
        "        for f in self.working_graph.get_factors():\n",
        "            # IMPLEMENT\n",
        "            for v in f.variables:\n",
        "              self.messages[f][v] = self.factor_ones(v)\n",
        "              self.messages[v][f] = self.factor_ones(v)\n",
        "\n",
        "                \n",
        "    def factor_to_variable(self, f, v):\n",
        "        \"\"\"\n",
        "        Computes message m from factor to variable. It computes it from all messages from all\n",
        "        other variables to the factor (i.e. all variables connected the factor except v).\n",
        "        Returns message m.\n",
        "        \"\"\"\n",
        "        assert v in self.variables and f in self.working_graph.factors\n",
        "        message = self.factor_ones(v)\n",
        "        \n",
        "        # IMPLEMENT\n",
        "        message*=f\n",
        "        vars = list()\n",
        "        for v2 in f.variables:\n",
        "          if v2 != v:\n",
        "            message*=self.messages[f][v2]\n",
        "            vars.append(v2)\n",
        "        message.marginalize(vars)\n",
        "        return message\n",
        "\n",
        "    def variable_to_factor(self, v, f):\n",
        "        \"\"\"\n",
        "        Computes message m from variable to factor. It computes it from all messages from all\n",
        "        other factors to the variable (i.e. all factors connected the variable except f).\n",
        "        Returns message m.\n",
        "        \"\"\"\n",
        "        assert v in self.variables and f in self.working_graph.factors\n",
        "        # IMPLEMENT\n",
        "        M = list(self.messages[v].values())\n",
        "        M.remove(self.messages[v][f])\n",
        "\n",
        "        return prod(M)\n",
        "    \n",
        "    def get_evidence_factors(self, evidence):\n",
        "        \"\"\"\n",
        "        For each evidence variable v, create a factor with p(v=e)=1. Recieves a dict of\n",
        "        evidence, where keys are variables and values are variable states. Returns a list of\n",
        "        DiscreteFactor.\n",
        "        \"\"\"\n",
        "        # IMPLEMENT\n",
        "        factors = list()\n",
        "        for key in evidence:\n",
        "          idx = self.state_names[key].index(evidence[key])\n",
        "          val = [0]*len(self.state_names[key])\n",
        "          val[idx] = 1\n",
        "          factors.append(DiscreteFactor(variables=[key],\n",
        "                        cardinality=[len(self.state_names[key])],\n",
        "                        values=val,\n",
        "                        state_names=self.state_names))\n",
        "        return factors\n",
        "        \n",
        "    def update(self, m_to, m_from):\n",
        "        \"\"\"\n",
        "        Performs an update of a message depending on whether it is variable-to-factor or\n",
        "        factor-to-variable.\n",
        "        \"\"\"\n",
        "        # IMPLEMENT\n",
        "        if m_to in self.working_graph.factors:\n",
        "          self.messages[m_to][m_from] = self.variable_to_factor(m_from,m_to)\n",
        "        else:\n",
        "          self.messages[m_to][m_from] = self.factor_to_variable(m_from,m_to)\n",
        "        \n",
        "        \n",
        "    \n",
        "    def collect_evidence(self, node, parent):\n",
        "        \"\"\"\n",
        "        Passes messages from the leaves to the root of the tree.\n",
        "        The parent argument is used to avoid an infinite recursion.\n",
        "        \"\"\"\n",
        "        for child in self.working_graph.neighbors(node):\n",
        "            # IMPLEMENT\n",
        "            if child != parent:\n",
        "                self.update(node, self.collect_evidence(child, node))\n",
        "        return node\n",
        "            \n",
        "    \n",
        "    def distribute_evidence(self, node, parent):\n",
        "        \"\"\"\n",
        "        Passes messages from the root to the leaves of the tree.\n",
        "        The parent argument is used to avoid an infinite recursion.\n",
        "        \"\"\"\n",
        "        for child in self.working_graph.neighbors(node):\n",
        "            # IMPLEMENT\n",
        "            if child != parent:\n",
        "                self.update(child, node)\n",
        "                self.distribute_evidence(child, node)\n",
        "    \n",
        "    def set_evidence(self, evidence):\n",
        "        \"\"\"\n",
        "        Generates a new graph with the evidence factors\n",
        "        evidence (keys: variables, values: states)\n",
        "        \"\"\"\n",
        "        evidence_factors = self.get_evidence_factors(evidence)\n",
        "        self.working_graph = self.original_graph.copy()\n",
        "        for f in evidence_factors:\n",
        "          # IMPLEMENT\n",
        "           self.working_graph.add_factors(f)\n",
        "           for v in f.variables:\n",
        "            self.working_graph.add_edge(f,v)\n",
        "\n",
        "        self.bp_done = False\n",
        "    \n",
        "    def run_bp(self, root):\n",
        "        \"\"\"\n",
        "        After initializing the messages, this function performs Belief Propagation\n",
        "        using collect_evidence and distribute_evidence from the given root node.\n",
        "        \"\"\"\n",
        "        assert root in self.variables, \"Variable not in the model\"\n",
        "        # IMPLEMENT\n",
        "        self.initialize_messages()\n",
        "        self.collect_evidence(root, None)\n",
        "        self.distribute_evidence(root, None)\n",
        "        self.bp_done = True\n",
        "\n",
        "    def get_marginal(self, variable):\n",
        "        \"\"\"\n",
        "        To be used after run_bp. Returns p(variable | evidence) unnormalized.\n",
        "        \"\"\"\n",
        "        assert self.bp_done, \"First run BP!\"\n",
        "        # IMPLEMENT\n",
        "        message = self.factor_ones(variable)\n",
        "        for f in self.working_graph.factors:\n",
        "          if variable in f.variables:\n",
        "            message*=self.messages[variable][f]\n",
        "        #return prod(list(self.messages[variable].values()))\n",
        "        return message"
      ],
      "metadata": {
        "id": "_o4eeICAn7ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8ak2V8a3Jxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289c3999-2010-4a3e-b4a7-5383a5fa3f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum probability: 0.16289702507051776\n",
            "State assignment: [('w0', 'rainy'), ('w1', 'cloudy'), ('w2', 'rainy')]\n"
          ]
        }
      ],
      "source": [
        "from pgmpy.inference import BeliefPropagation\n",
        "import numpy as np\n",
        "\n",
        "bp = BeliefPropagation(hmm_weather_3.to_factor_graph())\n",
        "# Compute the joint probability\n",
        "joint = bp.query(variables=['w0','w1','w2'],\n",
        "                 evidence={\"u0\":True,\"u1\":True, \"u2\":True})\n",
        "# Get the index of the maximum value\n",
        "amax = np.argmax(joint.values)\n",
        "print(\"Maximum probability:\", joint.values.flatten()[amax])\n",
        "print(\"State assignment:\", sorted(joint.assignment([amax])[0])) # pgmpy's assignment function gives us the states for the given index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kv52Egu3Jxu"
      },
      "source": [
        "## Task 1: Robot Navigation on a Grid\n",
        "\n",
        "In this problem, a robot is wandering through the following small world:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Rq-izqt8vkkkX6FbWrhaeCuGkgggJiPF\"  alt=\"A robot on a maze\" title=\"Title text\" width=350 height=350>\n",
        "\n",
        "The robot can only occupy the colored squares.  At each time step, the robot attempts to move up, down, left or right, where the choice of direction is made at random.  If the robot attempts to move onto a black square, or to leave the confines of its world, its action has no effect and it does not move at all.  The robot can only sense the color of the square it occupies.  However, its sensors are only $90\\%$ accurate, meaning that $10\\%$ of the time, it perceives a random color rather than the true color of the currently occupied square.  The robot begins each walk in a randomly chosen colored square.\n",
        "\n",
        "In this problem, state refers to the location of the robot in the world in x:y coordinates, and output refers to a perceived color (r, g, b or y).  Thus, a typical random walk looks like this:\n",
        "\n",
        "``3:3 r``\n",
        "``3:3 r``\n",
        "``3:4 y``\n",
        "``2:4 b``\n",
        "``3:4 y``\n",
        "``3:3 r``\n",
        "``2:3 b``\n",
        "``1:3 g``\n",
        "``2:3 b``\n",
        "``2:4 r``\n",
        "``3:4 y``\n",
        "``4:4 y``\n",
        "\n",
        "Here, the robot begins in square ``3:3`` perceiving red, attempts to make an illegal move (to the right), so stays in ``3:3``, still perceiving red.  On the next step, the robot moves up to ``3:4`` perceiving yellow, then left to ``2:4`` perceiving blue (erroneously), and so on.\n",
        "\n",
        "We will provide the HMM model for this world. Then, given only sensor information (i.e., a sequence of colors), you will have to answer different queries regarding the actual path taken by the robot through its world.\n",
        "\n",
        "The data for this problem is in [robot.data](files/robot.data), a file containing $200$ training sequences (random walks) and $200$ test sequences, each sequence consisting of $200$ steps.\n",
        "\n",
        "We provide next the implementation on how to build the HMM. First, we define some functions that will become handy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3wnnbc13Jxv"
      },
      "outputs": [],
      "source": [
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "def split(s, sep):\n",
        "    \"\"\"\n",
        "    Generator that splits a sequence s into subsequences, when separator sep is found.\n",
        "    \"\"\"\n",
        "    chunk = []\n",
        "    for val in s:\n",
        "        if val == sep:\n",
        "            yield chunk\n",
        "            chunk = []\n",
        "        else:\n",
        "            chunk.append(val)\n",
        "    yield chunk\n",
        "\n",
        "def to_cpd(phi, x):\n",
        "    \"\"\"\n",
        "    Returns a TabularCPD object from a DiscreteFactor. For a given factor phi(x_0, ..., x_n)\n",
        "    and a variable x_i, it interprets the factor as a CPD P(x_i|Y), where Y is the set of all\n",
        "    variables in phi except x_i. I.e. P(x_i|x_0, ..., x_{i-1}, x_{i+1}, ..., x_n).\n",
        "    It also checks that the factor is a valid conditional probability distribution.\n",
        "    \"\"\"\n",
        "    assert x in phi.variables\n",
        "    idx = phi.variables.index(x)\n",
        "    card = list(phi.cardinality)\n",
        "    var_card = card[idx]\n",
        "    evidence_card = card[:idx] + card[idx+1:]\n",
        "    values = np.moveaxis(phi.values, idx, 0) # move variable x to dimension 0\n",
        "    return TabularCPD(variable=x,\n",
        "                      variable_card=var_card,\n",
        "                      evidence=phi.variables[:idx] + phi.variables[idx+1:],\n",
        "                      evidence_card=evidence_card,\n",
        "                      values=values.reshape(var_card, int(np.prod(evidence_card))), # int cast since np.prod([])=1.0\n",
        "                      state_names=phi.state_names)\n",
        "\n",
        "def normalize_cpd_values(variables, cardinality, values):\n",
        "    \"\"\"\n",
        "    Normalize a numpy array of CPD values. It also accounts for unreachable states (all 0s).\n",
        "    \"\"\"\n",
        "    assert len(variables) in (1,2)\n",
        "    f = DiscreteFactor(variables=variables, cardinality=cardinality, values=values)\n",
        "    # Normalize it as a CPD\n",
        "    f = to_cpd(f, variables[-1]) # Get the last variable for the CPD (e.g. [ht-1, ht] -> p(ht|ht-1))\n",
        "    f.normalize()\n",
        "    # Remove NaNs, put 0s instead\n",
        "    f.values[np.logical_not(np.isfinite(f.values))] = 0.0\n",
        "    if len(f.variables) == 2:\n",
        "        # The process f->cpd swapped the variables, let's swap them back\n",
        "        assert f.variables[1] == variables[0]\n",
        "        return np.transpose(f.values)\n",
        "    return f.values\n",
        "    \n",
        "def get_hmm_factors(trajectories, h_states, v_states):\n",
        "    \"\"\"\n",
        "    Gets the prior, transition and observation probabilities of an HMM from data.\n",
        "    \"\"\"\n",
        "    prior = np.zeros(len(h_states))\n",
        "    transition = np.zeros([len(h_states), len(h_states)])\n",
        "    observation = np.zeros([len(h_states), len(v_states)])\n",
        "    for t in trajectories:\n",
        "        for i in range(len(t)):\n",
        "            s, o = t[i].split(\" \") # h and v come as a string \"h v\"\n",
        "            s_i, o_i = h_states.index(s), v_states.index(o)\n",
        "            if i == 0: # Prior\n",
        "                prior[s_i] += 1\n",
        "            else:\n",
        "                prev_s_i = h_states.index(t[i-1].split(\" \")[0])\n",
        "                transition[prev_s_i][s_i] += 1 # Transition\n",
        "            observation[s_i][o_i] += 1 # Observation\n",
        "\n",
        "    return normalize_cpd_values(['h0'], [len(h_states)], prior), \\\n",
        "           normalize_cpd_values(['ht-1', 'ht'], [len(h_states), len(h_states)], transition), \\\n",
        "           normalize_cpd_values(['ht', 'vt'], [len(h_states), len(v_states)], observation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daFL8Gwu3Jxw"
      },
      "source": [
        "Then, we extract the probabilities from the training sequences, and print one sample trajectory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "zE-MW19f3Jxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddec1cf9-d426-43a8-c1da-d7754ff4cd8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROBOT: 401 robot trajectories read.\n",
            "['2:4', '3:4', '3:4', '4:4', '4:4', '4:4', '4:4', '4:4', '4:4', '3:4']\n",
            "['r', 'y', 'y', 'b', 'b', 'r', 'b', 'b', 'b', 'y']\n"
          ]
        }
      ],
      "source": [
        "with open(\"robot.data\") as f:\n",
        "    robot_data = f.read().splitlines() # this accounts for '\\n'\n",
        "\n",
        "# Split into train and test data (separated by \"..\" in the file, end of single trajectory is marked with \".\")\n",
        "train_robot, test_robot = [list(split(dataset, '.')) for dataset in split(robot_data, '..')]\n",
        "print(f\"ROBOT: {len(train_robot) + len(test_robot)} robot trajectories read.\")\n",
        "\n",
        "size_square = 4\n",
        "positions = [f\"{x+1}:{y+1}\" for x in range(size_square) for y in range(size_square)]\n",
        "colors = ['r', 'g', 'b', 'y']\n",
        "r_prior, r_transition, r_observation = get_hmm_factors(trajectories = train_robot,\n",
        "                                                       h_states=positions,\n",
        "                                                       v_states=colors) # This will raise a warning: invalid value encountered in true_divide\n",
        "\n",
        "# Define factor functions\n",
        "def robot_prior(pos):\n",
        "    return DiscreteFactor(variables=[pos],\n",
        "                          cardinality=[len(positions)],\n",
        "                          values=r_prior,\n",
        "                          state_names = {pos: positions})\n",
        "\n",
        "def robot_transition(prev_pos, next_pos):\n",
        "    return DiscreteFactor(variables=[prev_pos, next_pos],\n",
        "                          cardinality=[len(positions), len(positions)],\n",
        "                          values=r_transition,\n",
        "                          state_names = {prev_pos: positions,\n",
        "                                         next_pos: positions})\n",
        "\n",
        "def robot_observation(pos, col):\n",
        "    return DiscreteFactor(variables=[pos, col],\n",
        "                          cardinality=[len(positions), len(colors)],\n",
        "                          values=r_observation,\n",
        "                          state_names = {pos: positions,\n",
        "                                         col: colors})\n",
        "\n",
        "robot_pos_trajectories = [[f\"{p.split(' ')[0]}\" for p in traj] for traj in test_robot][:-1] # last one is empty\n",
        "robot_color_trajectories = [[f\"{p.split(' ')[1]}\" for p in traj] for traj in test_robot][:-1]\n",
        "\n",
        "print(robot_pos_trajectories[-1][:10])\n",
        "print(robot_color_trajectories[-1][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IdeX5Lt3Jxx"
      },
      "source": [
        "### Questions\n",
        "\n",
        "Given the following sequence of observations $v_{1:T}$:\n",
        "```\n",
        "['g', 'g', 'b', 'r', 'r', 'b', 'b', 'r', 'r', 'y', 'r', 'b', 'r', 'y', 'b']\n",
        "```\n",
        "\n",
        "Answer the following questions using your implementation of belief propagation:\n",
        "1. Filtering : what is $p(h_6|v_{1:6})$?\n",
        "2. Prediction : what is $p(h_7|v_{1:6})$?\n",
        "3. Probability of evidence : what is $p(v_{1:T})$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPPmmEiQ3Jxy"
      },
      "outputs": [],
      "source": [
        "observed_colors = ['g', 'g', 'b', 'r', 'r', 'b', 'b', 'r', 'r', 'y', 'r', 'b', 'r', 'y', 'b']\n",
        "\n",
        "robot_HMM = HMM(n_vars=len(observed_colors),\n",
        "                prior_fn=robot_prior,\n",
        "                transition_fn=robot_transition,\n",
        "                observation_fn=robot_observation,\n",
        "                h_states=positions,\n",
        "                v_states=colors,\n",
        "                h_name=\"position\",\n",
        "                v_name=\"color\")\n",
        "##\n",
        "bp = BeliefPropagation(robot_HMM.to_factor_graph())\n",
        "my_bp = MyBeliefPropagation(robot_HMM.to_factor_graph())\n",
        "##"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## FILTERING\n",
        "my_bp = MyBeliefPropagation(robot_HMM.to_factor_graph())\n",
        "my_bp.set_evidence({\"color0\":'g',\"color1\":'g', \"color2\":'b', \"color3\":'r', \"color4\":'r', \"color5\":'b'})\n",
        "my_bp.run_bp(\"position5\")\n",
        "filtering1 = my_bp.get_marginal('position5')\n",
        "filtering1.normalize()\n",
        "print(\"p(h6|v1:6) is:\\n\", filtering1)\n",
        "##"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yytr22_ItEwg",
        "outputId": "4ca6994d-c46a-4a33-daff-b59f3b0c01c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(h6|v1:6) is:\n",
            " +----------------+------------------+\n",
            "| position5      |   phi(position5) |\n",
            "+================+==================+\n",
            "| position5(1:1) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(1:2) |           0.0109 |\n",
            "+----------------+------------------+\n",
            "| position5(1:3) |           0.0039 |\n",
            "+----------------+------------------+\n",
            "| position5(1:4) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(2:1) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(2:2) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(2:3) |           0.8905 |\n",
            "+----------------+------------------+\n",
            "| position5(2:4) |           0.0353 |\n",
            "+----------------+------------------+\n",
            "| position5(3:1) |           0.0002 |\n",
            "+----------------+------------------+\n",
            "| position5(3:2) |           0.0081 |\n",
            "+----------------+------------------+\n",
            "| position5(3:3) |           0.0092 |\n",
            "+----------------+------------------+\n",
            "| position5(3:4) |           0.0267 |\n",
            "+----------------+------------------+\n",
            "| position5(4:1) |           0.0006 |\n",
            "+----------------+------------------+\n",
            "| position5(4:2) |           0.0002 |\n",
            "+----------------+------------------+\n",
            "| position5(4:3) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(4:4) |           0.0143 |\n",
            "+----------------+------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_bp.set_evidence({\"color0\":'g',\"color1\":'g', \"color2\":'b', \"color3\":'r', \"color4\":'r', \"color5\":'b'})\n",
        "my_bp.run_bp('position6')\n",
        "prediction1 = my_bp.get_marginal('position6')\n",
        "prediction1.normalize()\n",
        "print(\"p(h7|v1:6) is:\\n\", prediction1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQsEXXl4zfDC",
        "outputId": "83e902af-9176-483a-e178-c38c51bd7471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(h7|v1:6) is:\n",
            " +----------------+------------------+\n",
            "| position6      |   phi(position6) |\n",
            "+================+==================+\n",
            "| position6(1:1) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position6(1:2) |           0.0093 |\n",
            "+----------------+------------------+\n",
            "| position6(1:3) |           0.2293 |\n",
            "+----------------+------------------+\n",
            "| position6(1:4) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position6(2:1) |           0.0001 |\n",
            "+----------------+------------------+\n",
            "| position6(2:2) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position6(2:3) |           0.2407 |\n",
            "+----------------+------------------+\n",
            "| position6(2:4) |           0.2473 |\n",
            "+----------------+------------------+\n",
            "| position6(3:1) |           0.0022 |\n",
            "+----------------+------------------+\n",
            "| position6(3:2) |           0.0045 |\n",
            "+----------------+------------------+\n",
            "| position6(3:3) |           0.2248 |\n",
            "+----------------+------------------+\n",
            "| position6(3:4) |           0.0220 |\n",
            "+----------------+------------------+\n",
            "| position6(4:1) |           0.0004 |\n",
            "+----------------+------------------+\n",
            "| position6(4:2) |           0.0023 |\n",
            "+----------------+------------------+\n",
            "| position6(4:3) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position6(4:4) |           0.0173 |\n",
            "+----------------+------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## EVIDENCE\n",
        "my_bp.set_evidence({\"color0\":'g',\"color1\":'g', \"color2\":'b', \"color3\":'r', \"color4\":'r', \"color5\":'b'})\n",
        "my_bp.run_bp('position0')\n",
        "evidence1 = my_bp.get_marginal('position5')\n",
        "#evidence1.normalize()\n",
        "print(\"p(v1:6) is:\\n\", sum(evidence1.values))\n",
        "##"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bilKHC6K0WUD",
        "outputId": "110f6ee3-f797-477f-efd0-79f190be433f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(v1:6) is:\n",
            " 0.0003538022794627493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bp = BeliefPropagation(robot_HMM.to_factor_graph())\n",
        "# Compare with library BP\n",
        "filt = bp.query(variables=[\"position5\"],\n",
        "                evidence={\"color0\":'g',\"color1\":'g', \"color2\":'b', \"color3\":'r', \"color4\":'r', \"color5\":'b'})\n",
        "print(filt)\n",
        "\n",
        "pred = bp.query(variables=[\"position6\"],\n",
        "                evidence={\"color0\":'g',\"color1\":'g', \"color2\":'b', \"color3\":'r', \"color4\":'r', \"color5\":'b'})\n",
        "print(pred)\n",
        "\n",
        "ev = bp.query(variables=[\"color0\",\"color1\", \"color2\", \"color3\", \"color4\", \"color5\"])\n",
        "ev.reduce([(\"color0\", 'g'), (\"color1\", 'g'), (\"color2\", 'b'), (\"color3\", 'r'), (\"color4\", 'r'), (\"color5\", 'b')])\n",
        "print(ev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr_7sNp3xud-",
        "outputId": "f62ba7ea-d52c-4971-a5a7-ff2064775bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+\n",
            "| position5      |   phi(position5) |\n",
            "+================+==================+\n",
            "| position5(1:1) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(1:2) |           0.0109 |\n",
            "+----------------+------------------+\n",
            "| position5(1:3) |           0.0039 |\n",
            "+----------------+------------------+\n",
            "| position5(1:4) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(2:1) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(2:2) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(2:3) |           0.8905 |\n",
            "+----------------+------------------+\n",
            "| position5(2:4) |           0.0353 |\n",
            "+----------------+------------------+\n",
            "| position5(3:1) |           0.0002 |\n",
            "+----------------+------------------+\n",
            "| position5(3:2) |           0.0081 |\n",
            "+----------------+------------------+\n",
            "| position5(3:3) |           0.0092 |\n",
            "+----------------+------------------+\n",
            "| position5(3:4) |           0.0267 |\n",
            "+----------------+------------------+\n",
            "| position5(4:1) |           0.0006 |\n",
            "+----------------+------------------+\n",
            "| position5(4:2) |           0.0002 |\n",
            "+----------------+------------------+\n",
            "| position5(4:3) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position5(4:4) |           0.0143 |\n",
            "+----------------+------------------+\n",
            "+----------------+------------------+\n",
            "| position6      |   phi(position6) |\n",
            "+================+==================+\n",
            "| position6(1:1) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position6(1:2) |           0.0093 |\n",
            "+----------------+------------------+\n",
            "| position6(1:3) |           0.2293 |\n",
            "+----------------+------------------+\n",
            "| position6(1:4) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position6(2:1) |           0.0001 |\n",
            "+----------------+------------------+\n",
            "| position6(2:2) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position6(2:3) |           0.2407 |\n",
            "+----------------+------------------+\n",
            "| position6(2:4) |           0.2473 |\n",
            "+----------------+------------------+\n",
            "| position6(3:1) |           0.0022 |\n",
            "+----------------+------------------+\n",
            "| position6(3:2) |           0.0045 |\n",
            "+----------------+------------------+\n",
            "| position6(3:3) |           0.2248 |\n",
            "+----------------+------------------+\n",
            "| position6(3:4) |           0.0220 |\n",
            "+----------------+------------------+\n",
            "| position6(4:1) |           0.0004 |\n",
            "+----------------+------------------+\n",
            "| position6(4:2) |           0.0023 |\n",
            "+----------------+------------------+\n",
            "| position6(4:3) |           0.0000 |\n",
            "+----------------+------------------+\n",
            "| position6(4:4) |           0.0173 |\n",
            "+----------------+------------------+\n",
            "+---------+\n",
            "|   phi() |\n",
            "+=========+\n",
            "|  0.0004 |\n",
            "+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, when comparing with the BP class from numpy library, we obtain the same exact joint distributions for the filtering and prediction (both nornalized) and the same probability for the evidence (though the library function returns it roudned to 4 decimal places)."
      ],
      "metadata": {
        "id": "lzLHheOFyF_W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_149nsY3Jxy"
      },
      "source": [
        "#### SOLUTION:\n",
        "Original trajectory:\n",
        "```\n",
        "robot_pos_trajectories[9][:15]\n",
        "['1:3', '1:3', '2:3', '2:4', '2:4', '2:3', '2:3', '2:4', '2:4', '3:4', '3:3', '2:3', '2:4', '3:4', '4:4']\n",
        "['g', 'g', 'b', 'r', 'r', 'b', 'b', 'r', 'r', 'y', 'r', 'b', 'r', 'y', 'b']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKjFRhMx3Jxz"
      },
      "source": [
        "## Task 2: Correcting typos without a dictionary\n",
        "\n",
        "The second domain deals with the problem of correcting typos in text without using a dictionary.  Here, you will be given text containing many typographical errors and the goal is to correct as many typos as possible.\n",
        "\n",
        "In this problem, state refers to the correct letter that should have been typed, and output refers to the actual letter that was typed.  Given a sequence of outputs (i.e., actually typed letters), the problem is to reconstruct the hidden state sequence (i.e., the intended sequence of letters).  Thus, data for this problem looks like this:\n",
        "\n",
        "<code>\n",
        "i i\n",
        "n n \n",
        "t t\n",
        "r r\n",
        "o o\n",
        "d x\n",
        "u u\n",
        "c c\n",
        "t t\n",
        "i i\n",
        "o i\n",
        "n n\n",
        "_ _\n",
        "t t\n",
        "h h\n",
        "e e\n",
        "_ _\n",
        "</code>\n",
        "\n",
        "\n",
        "where the left column is the correct text and the right column contains text with errors.\n",
        "\n",
        "Data for this problem was generated as follows: we started with a text document, in this case, the Unabomber's Manifesto, which was chosen not for political reasons, but as a convenient, on-line, single-author text of about the right length.  For simplicity, all numbers and punctuation were converted to white space and all letters converted to lower case.  The remaining text is a sequence only over the lower case letters and the space character, represented in the data files by an underscore character.  Next, typos were artificially added to the data as follows: with $90\\%$ probability, the correct letter is transcribed, but with $10\\%$ probability, a randomly chosen neighbor (on an ordinary physical keyboard) of the letter is transcribed instead.  Space characters are always transcribed correctly.  In a harder variant of the problem, the rate of errors is increased to $20\\%$.  The first (roughly) $20,000$ characters of the document have been set aside for testing.  The remaining $161,000$ characters are used for training.\n",
        "\n",
        "As an example, the original document begins:\n",
        "\n",
        "<code>introduction the industrial revolution and its consequences have been a disaster for the human race they have greatly increased the life expectancy of those of us who live in advanced countries but they have destabilized society\n",
        "</code>    \n",
        "    \n",
        "With $20\\%$ noise, it looks like this:\n",
        "\n",
        "<code>introductipn the industfial revolhtjon and its consequences bafw newn a diszster rkr the yumab race thdy have grwatky increased the ljte esoectandy od thosr of is who libe in advanced coubfries but they have fewtabipuzee xociwty</code>\n",
        "\n",
        "The error rate (fraction of  characters that are mistyped) is about $16.5\\%$ (less than $20\\%$ because space characters were not corrupted).\n",
        "\n",
        "Data for this part of the assignment is in [typos10.data](files/typos10.data) and [typos20.data](files/typos20.data), representing data generated with a $10\\%$ or $20\\%$ error rate, respectively.\n",
        "\n",
        "Next, we provide the code to get the HMM from the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVmFTP5d3Jxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53d648c-e13c-4b3a-82ae-536506c880e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TYPOS 10: 30558 words read.\n",
            "TYPOS 20: 30558 words read.\n",
            "Original text:  introduction the industrial revolution and its consequences have been a disaster for the human \n",
            "Typos 10% text: introxuctiin the ibdudtrial revokufuon anf its consequences ysfe been a disaster for the hyman \n",
            "Typos 20% text: introductipn the industfial revolhtjon and its consequences bafw newn a diszster rkr the yumab \n"
          ]
        }
      ],
      "source": [
        "# 10% error rate\n",
        "with open(\"typos10.data\") as f:\n",
        "    text_data = f.read().splitlines() # this accounts for '\\n'\n",
        "\n",
        "# Split into train and test data (separated by \"..\" in the file, end of single word is marked with \"_ _\")\n",
        "train_typos10, test_typos10 = [list(split(dataset, '_ _')) for dataset in split(text_data, '..')]\n",
        "print(f\"TYPOS 10: {len(train_typos10) + len(test_typos10)} words read.\")\n",
        "\n",
        "characters = [chr(i+97) for i in range(26)]\n",
        "t10_prior, t10_transition, t10_observation = get_hmm_factors(trajectories = train_typos10,\n",
        "                                                             h_states=characters,\n",
        "                                                             v_states=characters)\n",
        "\n",
        "# 20% error rate\n",
        "with open(\"typos20.data\") as f:\n",
        "    text_data = f.read().splitlines() # this accounts for '\\n'\n",
        "train_typos20, test_typos20 = [list(split(dataset, '_ _')) for dataset in split(text_data, '..')]\n",
        "print(f\"TYPOS 20: {len(train_typos20) + len(test_typos20)} words read.\")\n",
        "t20_prior, t20_transition, t20_observation = get_hmm_factors(trajectories = train_typos20,\n",
        "                                                             h_states=characters,\n",
        "                                                             v_states=characters)\n",
        "\n",
        "# Define factor functions\n",
        "def text10_prior(c):\n",
        "    return DiscreteFactor(variables=[c],\n",
        "                          cardinality=[len(characters)],\n",
        "                          values=t10_prior,\n",
        "                          state_names = {c: characters})\n",
        "\n",
        "def text10_transition(prev_c, next_c):\n",
        "    return DiscreteFactor(variables=[prev_c, next_c],\n",
        "                          cardinality=[len(characters), len(characters)],\n",
        "                          values=t10_transition,\n",
        "                          state_names = {prev_c: characters,\n",
        "                                         next_c: characters})\n",
        "\n",
        "def text10_observation(c, c_typed):\n",
        "    return DiscreteFactor(variables=[c, c_typed],\n",
        "                          cardinality=[len(characters), len(characters)],\n",
        "                          values=t10_observation,\n",
        "                          state_names = {c: characters,\n",
        "                                         c_typed: characters})\n",
        "\n",
        "def text20_prior(c):\n",
        "    return DiscreteFactor(variables=[c],\n",
        "                          cardinality=[len(characters)],\n",
        "                          values=t20_prior,\n",
        "                          state_names = {c: characters})\n",
        "\n",
        "def text20_transition(prev_c, next_c):\n",
        "    return DiscreteFactor(variables=[prev_c, next_c],\n",
        "                          cardinality=[len(characters), len(characters)],\n",
        "                          values=t20_transition,\n",
        "                          state_names = {prev_c: characters,\n",
        "                                         next_c: characters})\n",
        "\n",
        "def text20_observation(c, c_typed):\n",
        "    return DiscreteFactor(variables=[c, c_typed],\n",
        "                          cardinality=[len(characters), len(characters)],\n",
        "                          values=t20_observation,\n",
        "                          state_names = {c: characters,\n",
        "                                         c_typed: characters})\n",
        "\n",
        "# Get test text from dataset\n",
        "original_text = \" \".join([\"\".join([c.split(\" \")[0] for c in word]) for word in test_typos10])\n",
        "typos10_text = \" \".join([\"\".join([c.split(\" \")[1] for c in word]) for word in test_typos10])\n",
        "typos20_text = \" \".join([\"\".join([c.split(\" \")[1] for c in word]) for word in test_typos20])\n",
        "print(\"Original text: \", original_text[:95])\n",
        "print(\"Typos 10% text:\", typos10_text[:95])\n",
        "print(\"Typos 20% text:\", typos20_text[:95])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIGeK_1B3Jx0"
      },
      "source": [
        "### Questions\n",
        "\n",
        "Given the following sequence of observations $v_{1:T}$:\n",
        "```\n",
        "['i', 'n', 't', 'r', 'o', 'x', 'u', 'c', 't', 'i', 'i', 'n']\n",
        "```\n",
        "\n",
        "Answer the following questions:\n",
        "1. Filtering : what is $p(h_{11}|v_{1:11})$?\n",
        "2. Prediction : what is $p(h_{12}|v_{1:11})$?\n",
        "3. Probability of evidence : what is $p(v_{1:12})$?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x62ue_Kt3Jx0"
      },
      "outputs": [],
      "source": [
        "word = ['i', 'n', 't', 'r', 'o', 'x', 'u', 'c', 't', 'i', 'i', 'n']\n",
        "\n",
        "word_hmm = HMM(n_vars=len(word),\n",
        "               prior_fn=text10_prior,\n",
        "               transition_fn=text10_transition,\n",
        "               observation_fn=text10_observation,\n",
        "               h_states=characters,\n",
        "               v_states=characters,\n",
        "               h_name=\"c\",\n",
        "               v_name=\"c_typed\")\n",
        "##\n",
        "my_bp2 = MyBeliefPropagation(word_hmm.to_factor_graph())\n",
        "\n",
        "##"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## FILTERING\n",
        "my_bp2 = MyBeliefPropagation(word_hmm.to_factor_graph())\n",
        "my_bp2.set_evidence({\"c_typed0\":'i',\"c_typed1\":'n', \"c_typed2\":'t', \"c_typed3\":'r', \"c_typed4\":'o', \"c_typed5\":'x', \"c_typed6\":'u', \"c_typed7\":'c', \"c_typed8\":'t', \"c_typed9\":'i', \"c_typed10\":'i'})\n",
        "my_bp2.run_bp('c10')\n",
        "filtering2 = my_bp2.get_marginal('c10')\n",
        "filtering2.normalize()\n",
        "print(\"p(h11|v1:11) is:\\n\", filtering2)\n",
        "##"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AIdSCCqvOyx",
        "outputId": "8dcdc37d-e0b1-4fcd-9b98-9fa20ceacadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(h11|v1:11) is:\n",
            " +--------+------------+\n",
            "| c10    |   phi(c10) |\n",
            "+========+============+\n",
            "| c10(a) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(b) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(c) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(d) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(e) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(f) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(g) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(h) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(i) |     0.1140 |\n",
            "+--------+------------+\n",
            "| c10(j) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(k) |     0.0602 |\n",
            "+--------+------------+\n",
            "| c10(l) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(m) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(n) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(o) |     0.8078 |\n",
            "+--------+------------+\n",
            "| c10(p) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(q) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(r) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(s) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(t) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(u) |     0.0179 |\n",
            "+--------+------------+\n",
            "| c10(v) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(w) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(x) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(y) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(z) |     0.0000 |\n",
            "+--------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PREDICTION\n",
        "my_bp2.set_evidence({\"c_typed0\":'i',\"c_typed1\":'n', \"c_typed2\":'t', \"c_typed3\":'r', \"c_typed4\":'o', \"c_typed5\":'x', \"c_typed6\":'u', \"c_typed7\":'c', \"c_typed8\":'t', \"c_typed9\":'i', \"c_typed10\":'i'})\n",
        "my_bp2.run_bp('c11')\n",
        "prediction2 = my_bp2.get_marginal('c11')\n",
        "prediction2.normalize()\n",
        "print(\"p(h11|v1:11) is:\\n\", prediction2)\n",
        "##"
      ],
      "metadata": {
        "id": "dYM_Mjc6lGqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388e8b10-894f-4b81-a5f8-f92a998fc5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(h11|v1:11) is:\n",
            " +--------+------------+\n",
            "| c11    |   phi(c11) |\n",
            "+========+============+\n",
            "| c11(a) |     0.0122 |\n",
            "+--------+------------+\n",
            "| c11(b) |     0.0137 |\n",
            "+--------+------------+\n",
            "| c11(c) |     0.0461 |\n",
            "+--------+------------+\n",
            "| c11(d) |     0.0248 |\n",
            "+--------+------------+\n",
            "| c11(e) |     0.0445 |\n",
            "+--------+------------+\n",
            "| c11(f) |     0.0876 |\n",
            "+--------+------------+\n",
            "| c11(g) |     0.0334 |\n",
            "+--------+------------+\n",
            "| c11(h) |     0.0008 |\n",
            "+--------+------------+\n",
            "| c11(i) |     0.0243 |\n",
            "+--------+------------+\n",
            "| c11(j) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c11(k) |     0.0023 |\n",
            "+--------+------------+\n",
            "| c11(l) |     0.0645 |\n",
            "+--------+------------+\n",
            "| c11(m) |     0.0547 |\n",
            "+--------+------------+\n",
            "| c11(n) |     0.1787 |\n",
            "+--------+------------+\n",
            "| c11(o) |     0.0211 |\n",
            "+--------+------------+\n",
            "| c11(p) |     0.0323 |\n",
            "+--------+------------+\n",
            "| c11(q) |     0.0003 |\n",
            "+--------+------------+\n",
            "| c11(r) |     0.1265 |\n",
            "+--------+------------+\n",
            "| c11(s) |     0.0498 |\n",
            "+--------+------------+\n",
            "| c11(t) |     0.0545 |\n",
            "+--------+------------+\n",
            "| c11(u) |     0.0672 |\n",
            "+--------+------------+\n",
            "| c11(v) |     0.0205 |\n",
            "+--------+------------+\n",
            "| c11(w) |     0.0354 |\n",
            "+--------+------------+\n",
            "| c11(x) |     0.0004 |\n",
            "+--------+------------+\n",
            "| c11(y) |     0.0031 |\n",
            "+--------+------------+\n",
            "| c11(z) |     0.0014 |\n",
            "+--------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## EVIDENCE\n",
        "my_bp2.set_evidence({\"c_typed0\":'i',\"c_typed1\":'n', \"c_typed2\":'t', \"c_typed3\":'r', \"c_typed4\":'o', \"c_typed5\":'x', \"c_typed6\":'u', \"c_typed7\":'c', \"c_typed8\":'t', \"c_typed9\":'i', \"c_typed10\":'i', \"c_typed11\": 'n'})\n",
        "my_bp2.run_bp('c0')\n",
        "evidence2 = my_bp2.get_marginal('c11')\n",
        "print(\"p(v1:12) is:\\n\", sum(evidence2.values))\n",
        "##"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H280PAktsRyx",
        "outputId": "f7c4c955-e45b-4968-e405-ce1465cf5445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(v1:12) is:\n",
            " 4.907482236670567e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bp = BeliefPropagation(word_hmm.to_factor_graph())\n",
        "# Compare with library BP\n",
        "filt2 = bp.query(variables=[\"c10\"],\n",
        "                evidence={\"c_typed0\":'i',\"c_typed1\":'n', \"c_typed2\":'t', \"c_typed3\":'r', \"c_typed4\":'o', \"c_typed5\":'x', \"c_typed6\":'u', \"c_typed7\":'c', \"c_typed8\":'t', \"c_typed9\":'i', \"c_typed10\":'i'})\n",
        "print(filt2)\n",
        "\n",
        "pred2 = bp.query(variables=[\"c11\"],\n",
        "                evidence={\"c_typed0\":'i',\"c_typed1\":'n', \"c_typed2\":'t', \"c_typed3\":'r', \"c_typed4\":'o', \"c_typed5\":'x', \"c_typed6\":'u', \"c_typed7\":'c', \"c_typed8\":'t', \"c_typed9\":'i', \"c_typed10\":'i'})\n",
        "print(pred2)\n",
        "\n",
        "#ev2 = bp.query(variables=[\"c_typed0\", \"c_typed1\", \"c_typed2\", \"c_typed3\", \"c_typed4\", \"c_typed5\", \"c_typed6\", \"c_typed7\", \"c_typed8\", \"c_typed9\", \"c_typed10\", \"c_typed11\"])\n",
        "#ev2.reduce([(\"c_typed0\", 'i'), (\"c_typed1\",'n'), (\"c_typed2\",'t'), (\"c_typed3\",'r'), (\"c_typed4\",'o'), (\"c_typed5\", 'x'), (\"c_typed6\", 'u'), (\"c_typed7\", 'c'), (\"c_typed8\", 't'), (\"c_typed9\", 'i'), (\"c_typed10\", 'i'), (\"c_typed11\", 'n')])\n",
        "#print(ev2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH12VHq9sxfN",
        "outputId": "0ea26b77-4c92-4f3f-c2fd-69cd9fae17c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------+\n",
            "| c10    |   phi(c10) |\n",
            "+========+============+\n",
            "| c10(a) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(b) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(c) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(d) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(e) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(f) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(g) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(h) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(i) |     0.1140 |\n",
            "+--------+------------+\n",
            "| c10(j) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(k) |     0.0602 |\n",
            "+--------+------------+\n",
            "| c10(l) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(m) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(n) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(o) |     0.8078 |\n",
            "+--------+------------+\n",
            "| c10(p) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(q) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(r) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(s) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(t) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(u) |     0.0179 |\n",
            "+--------+------------+\n",
            "| c10(v) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(w) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(x) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(y) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c10(z) |     0.0000 |\n",
            "+--------+------------+\n",
            "+--------+------------+\n",
            "| c11    |   phi(c11) |\n",
            "+========+============+\n",
            "| c11(a) |     0.0122 |\n",
            "+--------+------------+\n",
            "| c11(b) |     0.0137 |\n",
            "+--------+------------+\n",
            "| c11(c) |     0.0461 |\n",
            "+--------+------------+\n",
            "| c11(d) |     0.0248 |\n",
            "+--------+------------+\n",
            "| c11(e) |     0.0445 |\n",
            "+--------+------------+\n",
            "| c11(f) |     0.0876 |\n",
            "+--------+------------+\n",
            "| c11(g) |     0.0334 |\n",
            "+--------+------------+\n",
            "| c11(h) |     0.0008 |\n",
            "+--------+------------+\n",
            "| c11(i) |     0.0243 |\n",
            "+--------+------------+\n",
            "| c11(j) |     0.0000 |\n",
            "+--------+------------+\n",
            "| c11(k) |     0.0023 |\n",
            "+--------+------------+\n",
            "| c11(l) |     0.0645 |\n",
            "+--------+------------+\n",
            "| c11(m) |     0.0547 |\n",
            "+--------+------------+\n",
            "| c11(n) |     0.1787 |\n",
            "+--------+------------+\n",
            "| c11(o) |     0.0211 |\n",
            "+--------+------------+\n",
            "| c11(p) |     0.0323 |\n",
            "+--------+------------+\n",
            "| c11(q) |     0.0003 |\n",
            "+--------+------------+\n",
            "| c11(r) |     0.1265 |\n",
            "+--------+------------+\n",
            "| c11(s) |     0.0498 |\n",
            "+--------+------------+\n",
            "| c11(t) |     0.0545 |\n",
            "+--------+------------+\n",
            "| c11(u) |     0.0672 |\n",
            "+--------+------------+\n",
            "| c11(v) |     0.0205 |\n",
            "+--------+------------+\n",
            "| c11(w) |     0.0354 |\n",
            "+--------+------------+\n",
            "| c11(x) |     0.0004 |\n",
            "+--------+------------+\n",
            "| c11(y) |     0.0031 |\n",
            "+--------+------------+\n",
            "| c11(z) |     0.0014 |\n",
            "+--------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, when comparing with the BP class from numpy library, we obtain the same exact joint distributions for the filtering and prediction (both nornalized) and the same probability for the evidence (though the library function returns it roudned to 4 decimal places)."
      ],
      "metadata": {
        "id": "g9Ef2rVcyYgU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vugs61BCzc6p"
      },
      "source": [
        "## The Viterbi algorithm\n",
        "\n",
        "We have seen how we can obtain the MAP query from a BP query, and how that approach did not scale. Let's implement now the Viterbi algorithm to perform MAP queries on a HMM. It consists of the following steps\n",
        "\n",
        "1. Compute the factors $\\mu_t$ that will recursively be used to obtain the maximum probability\n",
        "\n",
        "$$\\mu(h_{t-1}) = \\max_{h_t} p(v_t|h_t)p(h_t|h_{t-1})\\mu(h_t),\\qquad 2\\leq t\\leq T,$$\n",
        "$$\\mu(h_T) = 1.$$\n",
        "\n",
        "2. Obtain the desired maximum probability and backtrack to obtain the state trajectory $h^*_{1:T}$ using the previous computations\n",
        "\n",
        "$$p_\\text{max} = \\text{max}_{h_1} p(v_1|h_1)p(h_1)\\mu(h_1),$$\n",
        "$$h_1^* = \\text{argmax}_{h_1} p(v_1|h_1)p(h_1)\\mu(h_1),$$\n",
        "$$h_t^* = \\text{argmax}_{h_t} p(v_t|h_t)p(h_t|h_{t-1}^*)\\mu(h_t).$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMg8wVnTzc6s"
      },
      "outputs": [],
      "source": [
        "from networkx.algorithms.tree.mst import maximum_spanning_edges\n",
        "def factor_ones(v, state_names):\n",
        "    \"\"\"\n",
        "    Returns a DiscreteFactor with all ones for variable v with its domain defined in states_names.\n",
        "    \"\"\"\n",
        "    card = len(state_names[v])\n",
        "    return DiscreteFactor(variables=[v],\n",
        "                          cardinality=[card],\n",
        "                          values=np.ones(card),\n",
        "                          state_names=state_names)\n",
        "\n",
        "class Viterbi:\n",
        "    def max_and_argmax(self, f):\n",
        "        \"\"\"\n",
        "        Given a factor f, returns its maximum value and the corresponding assignment. We assume that f\n",
        "        is a DiscreteFactor of one variable.\n",
        "        \"\"\"\n",
        "        assert len(f.variables)==1, \"Factor connected to more than one variable: \"+str(f.variables)\n",
        "        v = f.variables[0]\n",
        "        am = np.argmax(f.values)\n",
        "        return f.values[am], list(f.state_names[v])[am]\n",
        "\n",
        "    def compute_messages(self, hmm, evidence):\n",
        "        \"\"\"\n",
        "        Given an HMM and the evidence (a list of states in order from left to right), compute the\n",
        "        messages (from right to left).\n",
        "        Returns a list of messages.\n",
        "        \"\"\"\n",
        "        n_vars = len(evidence)\n",
        "        messages = [None]*n_vars\n",
        "        \n",
        "        T = n_vars-1\n",
        "        for i in range(T,-1,-1):        # From right to left\n",
        "          if(i==T):\n",
        "            messages[T] = factor_ones(hmm.h[T],hmm.state_names)  # mu_0 initialized to 1  \n",
        "          else:\n",
        "            t = i+1                     # Index change\n",
        "            mu_t = messages[t]          # Previous message = previous mu\n",
        "            h_t_1 = hmm.h[t-1]          # h_t-1\n",
        "            h_t = hmm.h[t]              # h_t\n",
        "            v_t = hmm.v[t]              # v_t\n",
        "\n",
        "            f1 = hmm.f[(h_t,v_t)]       # CTD factor: p(v_t|h_t) \n",
        "            f2 = hmm.f[(h_t_1,h_t)]     # CTD factor: p(h_t|h_t-1) \n",
        "\n",
        "            f = (f1*f2*mu_t).reduce([(v_t,evidence[t])],False) # p(v_t|h_t)*p(h_t|h_t-1)*mu_t and applying the evidence \n",
        "            f = f.maximize([h_t],False)                        # factor where the prob is with h_t\n",
        "\n",
        "            messages[t-1] = f                 # setting the message t-1 to the max value\n",
        "        \n",
        "        assert all(m is not None for m in messages)\n",
        "        return messages\n",
        "    #\n",
        "\n",
        "    def backtrack(self, hmm, messages, evidence):\n",
        "        \"\"\"\n",
        "        Given an HMM, the messages (computed from right to left), and the evidence (a list of states\n",
        "        in order from left to right), it computes the MAP states as well as their value in the joint\n",
        "        distribution.\n",
        "        Returns a list of states and the joint probability of these states.\n",
        "        \"\"\"\n",
        "\n",
        "        # Initial state\n",
        "        mu_0 = messages[0]\n",
        "        h_1 = hmm.h[0] \n",
        "        v_1 = hmm.v[0]\n",
        "        f1 = hmm.f[(h_1,v_1)].reduce([(v_1,evidence[0])],False)\n",
        "        print(hmm.f[(h_1,v_1)].reduce([(v_1,evidence[0])],False).normalize())\n",
        "        f2 = hmm.f[(h_1)]\n",
        "        f = f1*f2*mu_0\n",
        "        \n",
        "\n",
        "        # Computing the joint and the state\n",
        "        joint, h0_opt = self.max_and_argmax(f)\n",
        "        map_h = [h0_opt]\n",
        "\n",
        "        for t in range(1, len(hmm.h)):\n",
        "          mu_t = messages[t]                  \n",
        "          h_t = hmm.h[t] \n",
        "          v_t = hmm.v[t]\n",
        "          h_t_1 = hmm.h[t-1] \n",
        "          f1 = hmm.f[(h_t,v_t)].reduce([(v_t,evidence[t])],False)    # reduce with the evidence\n",
        "          f2 = hmm.f[(h_t_1,h_t)].reduce([(h_t_1,map_h[t-1])],False) # reduce with the previous computed state\n",
        "          f = f1*f2*mu_t\n",
        "          \n",
        "          # Computing the state\n",
        "          _, h_opt = self.max_and_argmax(f)\n",
        "          map_h.append(h_opt)\n",
        "          \n",
        "        \n",
        "        return map_h, joint\n",
        "    \n",
        "    def map_query(self, hmm, evidence):\n",
        "        \"\"\"\n",
        "        Given an hmm and the evidence (a list of states in order from left to right), returns the\n",
        "        MAP states as well as the MAP probability.\n",
        "        \"\"\"\n",
        "        assert type(evidence) in (list, tuple), \"The evidence should be a list of observed states\"\n",
        "        assert len(evidence) == len(hmm.v), \"To get the MAP of the states we need the whole sequence of observed states\"\n",
        "        messages = self.compute_messages(hmm, evidence)\n",
        "        return self.backtrack(hmm, messages, evidence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDwr_nQIzc6t"
      },
      "source": [
        "### MAP queries in the Basic setting\n",
        "First we try it in our simple setting, and check that the result is the same as from the BP query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4701a5-c638-4d09-eb18-f1d6ac68b329",
        "id": "p6jaQcALzc6u"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "MAP states: ['rainy', 'cloudy', 'rainy']\n",
            "MAP prob: 0.03248999999999999\n"
          ]
        }
      ],
      "source": [
        "\n",
        "viterbi = Viterbi()\n",
        "map_states, map_prob = viterbi.map_query(hmm_weather_3, evidence=[True, True, True])\n",
        "print(\"MAP states:\", map_states)\n",
        "print(\"MAP prob:\", map_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi_9ORNXzc6v"
      },
      "source": [
        "How does this method compare, in terms of complexity, to our previous, naive, approach?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deZZS8Rqzc6v"
      },
      "source": [
        "The Viterbi algorithm even if in normal cases is less efficient than the Belief Propagation, if we are talking about finding the most suitable sequence of hidden states. This is because, the dynamic programming of the Viterbi efficiently computes the states exploiting the structure of HMM.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsX10jnFzc6w"
      },
      "source": [
        "### MAP queries in the robot navigation setting\n",
        "\n",
        "To try it in the robot navigation setting, let's first define the DiscreteFactor functions for the HMM model, according to the values extracted from the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20NSiw8xzc6w",
        "outputId": "330c4bd0-b530-4119-f5b2-2fde0207a926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traj: ['g', 'g', 'r', 'r', 'g', 'r', 'g', 'g', 'r', 'r', 'g', 'r', 'r', 'r', 'r', 'r', 'g', 'r', 'b', 'g', 'g', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'b', 'y', 'r', 'g', 'r', 'r', 'g', 'g', 'r', 'r', 'r', 'r', 'r', 'g', 'g', 'g', 'b', 'b', 'r', 'b', 'g', 'g', 'g', 'g', 'g', 'y', 'b', 'b', 'y', 'g', 'y', 'y', 'y', 'b', 'y', 'g', 'y', 'g', 'g', 'r', 'b', 'g', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'g', 'g', 'b', 'r', 'r', 'r', 'b', 'r', 'y', 'y', 'g', 'g', 'b', 'r', 'r', 'b', 'g', 'b', 'g', 'r', 'y', 'r', 'y', 'b', 'g', 'r', 'b', 'r', 'y', 'b', 'y', 'y', 'r', 'g', 'b', 'y', 'y', 'y', 'g', 'b', 'y', 'b', 'b', 'b', 'y', 'g', 'y', 'b', 'y', 'g', 'y', 'y', 'b', 'b', 'y', 'y', 'y', 'b', 'b', 'y', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'y', 'y', 'y', 'r', 'y', 'y', 'g', 'y', 'y', 'r', 'g', 'g', 'b', 'b', 'b', 'b', 'b', 'b', 'y', 'y', 'y', 'g', 'r', 'b', 'g', 'g', 'g', 'g', 'g', 'b', 'r', 'b', 'b', 'b', 'g', 'g', 'b', 'r', 'b', 'r', 'b', 'g', 'y', 'b']\n",
            "Infered traj.:  ['1:3', '1:3', '1:2', '1:2', '1:3', '1:2', '1:3', '1:3', '1:2', '1:2', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '2:3', '2:3', '2:4', '2:3', '3:3', '3:2', '3:2', '3:2', '3:2', '4:2', '4:1', '4:1', '3:1', '3:2', '4:2', '4:2', '4:2', '4:1', '3:1', '2:1', '3:1', '3:2', '3:2', '3:3', '2:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '2:3', '2:4', '2:4', '2:4', '2:3', '2:4', '2:3', '1:3', '1:3', '1:3', '2:3', '2:4', '2:4', '2:3', '1:3', '2:3', '2:4', '2:4', '3:4', '2:4', '3:4', '3:3', '3:2', '3:3', '2:3', '2:4', '3:4', '4:4', '3:4', '3:4', '3:3', '3:2', '4:2', '4:2', '4:2', '4:2', '3:2', '4:2', '4:2', '4:1', '4:1', '4:1', '3:1', '3:2', '4:2', '4:1', '3:1', '3:2', '4:2', '4:2', '4:1', '4:1', '4:2', '4:2', '4:2', '4:1', '4:1', '4:2', '4:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:2', '4:2', '4:2', '4:2', '4:2', '4:2', '3:2', '3:1', '3:1', '2:1', '2:1', '2:1', '3:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:2', '4:2', '4:2', '3:2', '3:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:3', '2:3', '2:4', '2:3', '2:3', '2:3', '1:3', '1:3', '2:3', '2:4', '2:3', '2:4', '2:3', '1:3', '1:3', '2:3']\n",
            "Solution:       ['1:3', '1:3', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '1:3', '2:3', '2:3', '3:3', '3:2', '3:2', '3:2', '3:2', '3:2', '3:2', '4:2', '4:1', '4:1', '3:1', '3:2', '4:2', '4:2', '4:2', '4:1', '3:1', '2:1', '3:1', '3:2', '3:2', '3:3', '2:3', '1:3', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:2', '1:3', '1:3', '2:3', '2:4', '2:4', '2:4', '2:4', '2:4', '2:3', '1:3', '1:3', '1:3', '2:3', '2:4', '2:4', '2:3', '1:3', '2:3', '3:3', '3:3', '3:4', '3:3', '3:4', '3:3', '3:2', '3:3', '2:3', '2:4', '3:4', '4:4', '3:4', '3:4', '3:3', '3:2', '4:2', '4:2', '4:2', '4:2', '4:1', '4:1', '3:1', '4:1', '4:1', '4:1', '3:1', '2:1', '3:1', '4:1', '3:1', '3:2', '3:1', '3:1', '4:1', '4:1', '4:2', '4:2', '4:2', '4:1', '4:1', '3:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:2', '4:2', '4:2', '4:1', '4:2', '4:2', '4:2', '4:2', '4:2', '4:2', '3:2', '4:2', '4:1', '4:1', '4:1', '4:1', '4:1', '4:1', '4:2', '4:2', '4:2', '3:2', '3:3', '2:3', '1:3', '1:3', '1:3', '1:3', '1:3', '2:3', '2:4', '2:3', '2:3', '2:3', '1:3', '1:3', '2:3', '2:4', '2:3', '3:3', '2:3', '1:3', '2:3', '2:3']\n",
            "MAP value: 3.9714482937308246e-115\n",
            "Error: 0.145\n"
          ]
        }
      ],
      "source": [
        "observed_colors = robot_color_trajectories[4]\n",
        "actual_trajectory = robot_pos_trajectories[4]\n",
        "\n",
        "##\n",
        "robot_HMM = HMM(n_vars=len(observed_colors),\n",
        "                prior_fn=robot_prior,\n",
        "                transition_fn=robot_transition,\n",
        "                observation_fn=robot_observation,\n",
        "                h_states=positions,\n",
        "                v_states=colors,\n",
        "                h_name=\"position\",\n",
        "                v_name=\"color\")\n",
        "map_states, map_value = viterbi.map_query(robot_HMM, evidence=observed_colors)\n",
        "##\n",
        "\n",
        "print(\"Traj:\", observed_colors)\n",
        "print(\"Infered traj.: \", map_states)\n",
        "print(\"Solution:      \", actual_trajectory)\n",
        "print(\"MAP value:\", map_value)\n",
        "\n",
        "def error(t1, t2):\n",
        "    error = 0\n",
        "    for c1, c2 in zip(t1, t2):\n",
        "        if c1 != c2:\n",
        "            error += 1\n",
        "    return error/len(t1)\n",
        "\n",
        "print(\"Error:\", error(map_states, actual_trajectory))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt8uX7PWzc6x"
      },
      "source": [
        "### MAP queries in the typo correction setting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbaUueZDzc6y"
      },
      "source": [
        "Correct the following word containing typos with the HMM: ['i','n','t','r','o','x','u','c','t','i','i','n']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDvMVAnxzc6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12e7313-b474-4e2c-996f-0db2a9bf2753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'n', 't', 'r', 'o', 's', 'u', 'c', 't', 'i', 'o', 'n']\n",
            "1.0923058744369888e-16\n"
          ]
        }
      ],
      "source": [
        "word = ['i','n','t','r','o','x','u','c','t','i','i','n']\n",
        "map_states, map_value = viterbi.map_query(word_hmm, evidence=word)\n",
        "\n",
        "print(map_states)\n",
        "print(map_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9GlZ5mrzc6z"
      },
      "source": [
        "Now, let's correct the full text. We have the original text and the one that contains typos in the variables original_text and typos10_text respectively. We provide a function above to test the error between two texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLWKxiMvzc60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9085327-420f-42a4-cdca-003c59236db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "introxuctiin the ibdudtrial revokufuon anf its consequences ysfe been a disaster for the hyman race tyey habe hreztoy increasrs the life expdctancy of those of us who live jn advanced cluntries but tjey have festabilosed society have made lkfe unfulfilling have submected human beihgs go indignities have led to wixesprdad psycbologiczl sufferinf im the rhirf world to ohysucal suffering as welp and have inclicted severe damage on the natural world the dontinued eevelopment of techbology will worsem the situatkon it wupl vertainly subject human veings to greater indignitied and inflict greater damate on the natural world it aill pribsbly lead to greater sockal disruprion ane psychological suffeding and kt may kead to increawed physical sufrerinf evem ih advanced dkuntries the industrial technoligical system may survive or it mag break down jf it survives it may evrntually acyieve a low level or physical and psycnopogucak suftering but only after passihg througg a long and very oainful period of adjustnent amd only at the cost of permanently reducing buman beings anf many other living organisms to engineerrd pfoducts and mere cogs in the socisl machind furthermorr if the system survibea the conzeauejces will be knevitzhle there ks nl wzy of refprming or modiryimg the sgstem so ad to prwvejt it drom depriving people of dignity ajd sutknomy if thw system breals down tje conseqhenxes will still be very painful but the bigger the zystem grows the jore xisastrous the feaults of its breakdown will be so if it is to brezk dowm iy had best brwak down sooner tatber than latet we gherefote advocate a tegolutikn agaijst ghe ijdustfial system this regolution may or may not makw use of violwnce it may be sjddem od it mah be a eelatively gradusl ldocess spanning q few dexadea wr can t predict any lt that but we do oytline in a very generao way yhe jeasures tbqt thosd who hate the industrial system should take ij lrder to prepare the way for a revolution against that fodm of skciety this is not to be a politjcal revolutkon its ogject will he to overthrow not goverbmwnts but thw dfononic and twcynoloticao basis if the prwsenf society in this arfjcle wr givr atrentioh to only some of the negagjge developments tjat have growm out ot the indystrial technological systwm other such developments wr menrion only briegly or ignore alfogether tnis does not mean thst qe regard tjese other dwvelopments as unimportant for pracfical reasoms we have tk confine our discussion to areas that bave received insufficient public atrention or in which we have zomdthing new yo say foe example since therd are wrll developed rnvirlnmentsl and wilderness movekents we hafe wrotten very ligtle about wnvuronmental degradation or the destduction of wils nature even fhough we consicer these to be highoy importaht the psychology of modern peftisk almost evwryone will agree that we live in s dedply troublrd spckety one if the most audespread manifestations of the craziness of iyr worlx is lwfrisj so a diwcusdiom of the pzychologu of leftism can servd as sn intrlductiob to the discusxion of the proboems of kodern soxiety in genersl but what is leftism durimg the cirst halv of rhe rh fengury leftism could hqve been practically odentifird wifg socialism today fhe movement is fragmented and it is not cldar who can propetly be cslled a lettisf whwn we speak lf leftists in rhis article we hsve in njnd mainly slcialists collectivists politically correvt types feminiwts gay snd disabolity activists animsl tughts activists and the lome bur not everykhe who is awsociatrd with one of theze kovements is a leftuxt what we are tdying to gef at in discussing leftism is nkt so much a movement or an udwology as q psychological type pr rzther a coloectikj of relatws typez thuw what we mean bu leftism will emergw more clearlh in the xourse og our discussion oc leftisg psycyology qlso see paratrsphs even so our conceotkon of lwftism will remain a good deal less clear than we woulx wosh buf there doesm t seem to be any remedy gor thiw alk we are tryinf to do is indicate in a rough and approximate way the gwo psychological tendencies thzt we believe sre the main driving force of modern leftism we by no means claim to be tellint the whole truth avout leftist psycholovy alao pur djsdussuon is meany ti apply to modern leftism lnly we pwave open the question of ghe ectent ro which oir discussion could be applied to the leftists of the th and darlh tb dejtury the two psychologival tenfencies that underlie modern leftism we call fedlings of inferiprity and oversocializatiin feelingz of inveriority are characterkstoc of modern leftism as a sgope while oversociapizatjon us vharacterkstic omly of a certain swgkent of mkdern lefyisn but rhis segmwnt is hkghky influebtial feelingw of unferiority by feelings of inferiorkty we mran not only inferiority feelings in the strictest wrnse but a whole spectrum of relsted traits lps self esteem feelings of pkwdrlessmess fepreszive temdencies defeatism guiot sepf jatfed etc we argue tyat moderj leftjsfs tend go have sucj feelings possibly mpre oe less repressdd and that thwse feekibbs are secidjve in xeterkining the firection kf modrrn lettism whem simeine onterprets qs derpgatory almkst anything that is said about him or zbout groups with whom hr identifies we conclude tyat he has infwriofity feelinhs or low self esteem this tendency is prlnounfed akong minoriry rights advocates whetnee or not tbey belong to the minoroty grojps whlse rivhts thdy defend they are hypersensitivr about the eofds used tl desigjate minorities gje terms negro oriental handicapped or chifk flr an african an asian a disablwd oersln or q woman orkginally hzd no derogatory connotation broad and cnick were merely the feminine equivalents of guh dude or felkow fne negative connotations have beeh zttaches to these yerms by the activusts themselves some qnimal rights adcocatea have gone so far as to rejdct rhw word pet ane insjst in itx replavwment by animal companion leftist anthrolologists gk to grwat lengths to avoid daying anything about primitive peoplds that could conceivahly be interpreted as negative they want to rrplace the wofd ptimitive by honlitdraye they seem almost paranoid about anything tgat mighy suggest fhat ajy primitive cultute is inferior to oyd kwn we do not mean to impoy thay primitive cultures are incerior to ours we merdly point out the hyperswnsiticity of leftish anthropilogists those who are mpst sensutibe about politically incorrect twrmijology are not the avdrage black ghetto dweller asian immigrant znused wkman or disabled pefson hut s minoriry of activists many of whom do not even bdlong to any oppressdd gtoup but come rrok ptibilebed zteata of society poliyiczl corrrdtness has itx stronghpld smong unifeeaity profdsaors wjo have secure emlloyment wiyh comrortable salqries and the majority of whom are hetetosexual white males feom midfle flsss families many legtists gave aj intensr idejgifivation with the problems of gfohps thag hqvd an inagd of being weak women defeated ametican kndians repellent homosexuals or otherwise inferiot yhe leftizts themselves feel that these groups are interior tyey wljkd never aemit it to themselves thzt thwy have such feelings nut it is precisely becayse tjey do see thwse groups as inferior that they identify with their problems we do not suggest that women ineians etc are inferior ww are knlh making a loint qbout leftist psychology fekinists are desperately anxioua to provr that qonen are as strong as capahle as men clearly they are nagged by a fear that women kah hot be as strong and as cqpable as men leftidts tend to hate anything that has zn image od being strong food and sufcessful they hate amerixq they hare weztdrn civilization they hzte white kales tney hate rarionality thr reaaons thag leftists give for hating the west etc cpearly do not correxpond with their real motived thet say they hate the west because it iw waroike imperialjsruc secist dthnocemtric and so forth but wjdre these same faukts appear in sicialkst countrids or in primitive vultures the leftist finds excuses for them kr at nezt hd grudgingly admits fhat they exist wherezs he enthusiastifally points oht and ovten greztky exaggerztes ghese faults wherd they apprar in western civilization thus it is clear that these fauots are not the leftist a real motive for hatohg americs abd the wwxt he hztes akerica and the eest because they are strong and successful wlrds like selv confidence self reliance initiative enterorise optimism etc llzy little rolw in the liberal and leftist vocabulaey the leftist id anti ibdividualistic pro collrctivisr hr wants wociety to solve everyone s needs for thek take cate of then he is not tbr sorf of lerson qho has an inber sdnse of donfidrnce in his oqn ability to solve his own problems and satisfy his oqn needs the lectist is angagonistif to the concept of comletition bdcause deeo inaidr he feels like a loder art forms thay appeal to nodern leftist intrllectuals tend to focus oh sordidness defeat and despair or elsr tbeh tqke an prgiastic tone thriwing off rationap cpntrol as if there were no hope of accomllishing anhthing throubh ratiojal dalculation and aol tnat was lect was to immrrse oneselt ij thw sensations of the moment jldern legtist ohikosophers tend yo dixmusw rwason dcience objectife reality amd tl insisf thqt everything is cultutaklt delativw ot is true that one can ask sedious queztions ahout the foundations pf scientific knowledge and about how if at all the comcept ov objdctive reality cah be defined bug ut is obvious that mofwrn lefyisy philosopheds ate nor simply cool neadee logicians systematocally snalyzing the foundations of knowledge they ade deeply ijbolved emotuonally in their attack on trutn znf reality they attack these cknceptx because of yhrir owm psychological neefd for ohe thing yheor attzck is an ohtlet for hostility and to the extent that it is succeszful it safisfiws tjd drive for power more importangly the leftist hates science and rationapity because they classifh ceftain belirfs as trhw i e successful superior and other beliets as false i e tauled inferior the leftist s feeljngs of inferiprity fun so deep that he cqnnof tolerzte any vlassification of some thinfs aa successful or superioe and itner thjbts zs failed kf inferior this also hjderlirs the rejectkon nh many leftistx of the concept of mental kllness snc of the utipity of iw tesrz ledtidts qre antagonistkc to genetic explamatiohs of human abiluties or vehavior hecause such explanations tend to make some persons appear superior or incerior to orjers leftists prefer to fkve siviety the credit or nlame for an indivoduak s ability or lack of it thus if a person is inferior it is not his fault but society s vecause he gas not been brought ip properly the oeftist is not thpically the kind or person whose feelijgs of inferiority make hij a hraggart an egotist a bullg a seof projoter a ruyhless competitor this kkne ov peeson hss not wholly poat faith in himself he has a deficit in bis sense of power and self worth bug he xan sriol conceive of gimsepr as having ghe capacoyy to be steong and yis efforts ti make himself dtrong ptodyce his unplrawant bejavior but the leftist is too far gone for that his reeljhgs of inferikrigy are sl ingrzined that he cannot conceive of hkmsekf ad individually strkng and vakhavle hence tnr cillectivism of yhe leftist he can feel strong ojly ss s membee of a karge prganization or q mass movejrnt with which he idenyifies himself notice the maaochistic tendency of leftist tsctics lertusts pfoyesr ny lying cosn in rront ot vehicles they intenrionally provokr police or racists tl abhse them etc theze tactixs may often be effectuve bur mamy leftists usr them not as a meqns to aj end but because tney prefer masochixtic yaftica self hatrdd is a leftisg trait peftists nay claim that yyeir actkvism is motivated by compassion or by motao principle and moral peihciple does play a role for ghe leftist of the ofersocialkzed type but comoassion and moral principle cannot be thd jain motives for pwfrixt activism hostility is toi prominebt a component of leftist behavior so ia thr xrive foe power moreovdr mudh leftist behaviod is not ratilnally fzlculated to be of benefit to the pwople whom the leftists xlaim to be trying to help vor exanple if one beoiwves that affirmqtivw action is good for black peopoe does it maje sense to demand affirmatifr action in gostile or dogmatic ferms obfiously it woyld be more profuctive to takw a dkplomatic and conciliatory zpproach that aould make zt least verbql and symbolic condewsions to whife peopoe who think that affirmative action discriminates against fhem but leftist sctiviwts dl not take such an approaxh because it would not satisfy their empyiomap nreds helping black peoplr is not tjeir deal voal instead eace problems serve as an excuse for them to exprrss their owh hostkkity and frudyrarwd need for power in doing so they actuqlly harm blqck peiplw because the activists hostile attitude toward the white majorkty twnds to intensift racr hatred if our society had no socjap proglema at akl tne leftustx would have to invejt problemx in ordef to prpvice themselves with an excuse for jaking a fuss we emphqsize ghat yhe foregoing soes not pfetend to be an qccurate sescrjption if everyone whk might ne cojsisered a leftist ir is onlt a rough indicarion of a general tendency kf leftizm oversocualization psychologists use the term sovizlization to dewignate the process hy which children are trained tp think and act as society demajds a oerson is sajd to be well socialixed if he helieves in qnd pbeys the moral code of hks societt and fita in well as a fumctioning part of that society it may seem senzeless to aay that manu lectists are ovwr socoapized aince the leftist is oerceivef as a renrl nevertheless the position can be defended mabg leftistz are nor such rdbels as they serm the morql cose of ohr society is so demancjng that no one can thjnk feel and act ih a completely morak way for example ww are not suppozed tl hqte angone get apnost everyone hztes sonebody at skmr time or othdr whegher he admits kt to himsdof or nof wome pwople are so highly socialized ygat the attempt to think feel and act morally imposes a swgere burden on them im order to agoid feelings of guilt they continually hagw to dexeivd thwmsdkbed about their kwn motives and find mkrql exolanations fpr fewlings and actions that in reakity havd a non moral lrigin we ise the term oversocialized to fescribe such peoplw oversocialization cqn lead to oow sepc esteem a sense of powerlessnrss defeatism guikt etc one of the most important mwanw by shich our spcieyy socializes children is ny maming them feel ashaned of behavior or speech that is contrary to society s expevtations ig rhis is overxone or if a partkcular child os eapeciqlky susceptibke to auch fdelinfs gw endd bg geeking sshamed if himselc kofeover the thought and the nehavior of the obersockaoized person qre mlre restricted by society s ecpwdtayiibs thzn are those of rhe lugytly socialized prrson the majority of people ebgage in a skgnififant amount of naughty bejavior thru lie tjwy xommiy oetty thefts they hteak traffic laws rheg goof off at work they hate someonr they say spiteful tjihhs or rhey use somr undrejanded trick to get aheaf of the oyher guy tye oversocoalized pdraon cannot do thwse things od if he doew do thwm ne generates in hkjsepf a sense of shame and self hatred the oversocialized ldrspn cannot even expdrience withoyt guilt thoufhts or feelings that qte contrary tl the accepted moraoity be cannot think unclean thoughta and sociakizatiin is not juwt a matter of moraljty we are wociakizes to conrirm yo many norms of bdhavipr that do nor caol hnder the headkng of morality fhus the oversocialized person is iept on a pshchologicsl leaxh and spends his lice running on rails that societu has laid down for him in many lversocialized people this results in a senae lf cinstraint and powerlessness that cqn be a sevefr hardship se suggest thay oversofializatioh is amonb tbe more seriohs cruepries that human bdongs infpict on one amother we argue tjay a vrry imlortant and infljential segmehf of tge modern left is oversocialized and that their overzockalizatiin is of gfeat importance kn determining the direction of modern lwgtism leftists of the oversocialized tgpe teje to be intellectuaps or kembers of tye uppdr middle class notice that unoversity intrllectuals constitute the most highly socialoxec segment pf our society and also the most left wing segmenf the leftist of the oversocializws type tries gi get off hix psychooogical peash and assert his autonomy by rebelling but usually he iz not strong ejough to rebel agsinst the mozt basic values of socirty generally speaking rhe gials of today s ledtists are nlt in cobfljct with the accepted morality on the contrary the left takes an acfepted moral princuplr adopts it as ita own abd then adcuses maundtream societg od violating thaf peihciple examples radiql equaooty eaualiry of the sexes helpknh poor peiple peace as opposed yo war nknvoolence generally freedom of expfession kindness to animals moee fundamebtalky the dhty of ghe indivisual to serfe society amd thd dhty kf wociety to tsle csre of the individual all tjdse have beeh deelly rooted values of lur woxiety or at least of irs middle qnd ulper clawses for a long timr these values ard ezplicitly or implicitly expressed or presupposed in most of the material presrnted to us ny the mainstrean cokmunications media and the educationsl system leftists rspecizlly those of the ovedsodialized typr ysually fo not rebel against these princopkes but justify their hostiligy to society by claiming with somr degrer of truth that society is not pigung up to these lrinciples hrre is an ilkustrstion of the way in whicg tye iberdociaoisdf leftist shpws his real sgtachment to fhr conventional attiyudws of our society while prefendimg to be ih rebwllion qgainst it many leftists push for sffirmative action fkt moving black pepple into higy oresyigr jlbs cor improved education in blavk schools and mord minwy for such schkols the wzy of life of the black uhderclawa rhey regqrd as a social siwgtace theh want tl integrate the black man into the system make him a business exrcutive a lzwyer a sciebfist just like upprr midele class white pdoold the leftists will reply that tje last tninf they want is to make the black man intp a copy of the wyite kan instdad thwy wqnt to prewerve adrivan amdriczn culture but in what does this preswrvation of zfricah amerifan culture conajst it can hardly consist in anything mord than eatinh black style food listehing to black stylw music wearing boack sttle clothing and going to a black style churfh or mosque on other words it can express itself only in supefficial mstgers in alo rswentizl respects more lettists of thw pversociapizex gype want to make the bladk jan fonform gp white mjedpe class ideals fhey want to make gim stjdt technical subjects become aj esecutive od q scirntust spebd his life climbing the starus ladder to prove that bpsck people are as goof as white rhey eant to makw bpacj fathets responsible tgdy want black gangs to become nonviolent etc bjt thwse are exactly the values of the industrial technologifal system the ststem ciuldn g cqre less wjat lind of kusic a mzn lixtend to what kind of clothes he wears or ahat religion he believes in as long ad he studies in school holxs a respectahle job climbs thw wtatus lsdxer is a responsible parent kz nonvoolent and so fktth in effect hpwever much he may ddny jt the ocersocialused peftjwt sants to intehrate the black man onto tne system and make him adipt kts values we cerfainly dk nkt claim that leftists evem of the oversocualizwd type mever tebel against the funxamejtal values of our society clesrly tgey sometimed do some oversocialized lrftistw have gphe so far as to drbel sgainsf oje of modern soxiegu s mosr implrfant principles by engabkng in ohysical violenve\n",
            "introsuction the industrial revomufion anf its consequences ysfe been a disaster for the hyman race tyey habe hrestoy increases the life expectancy of those of us who live in advanced cluntries but they have festabilosed society have made lofe unfulfilling have sunmected human beings go indignities have led to wisesprdad psychological sufferinf im the thirf world to onysucal suffering as well and have inclicted severe damage on the natural world the dontinued eevelopment of technology will worsem the situation it supl vertainly subject human veings to greater indignitied and inflict greater damate on the natural world it aill pribably lead to greater social distuprion ane psychological suffeding and it may kead to increawed physical sufrerinf evem in advanced dountries the industrial technoligical system may survive or it mag break down if it survives it may eventually actieve a low level or physical and psychopogucak suftering but only after passing througg a long and very owinful period of adjusthent and only at the cost of permanently reducing buman beings anf many other living organisms to engineered ofoducts and mere cogs in the socisl machind furthermorr if the system survibea the conseauences will be inevitable there is nl way of reforming or modirying the system so ad to prevent it drom depriving people of dignity and sutinomy if the system breals down the consewhendes will still be very painful but the bigger the aystem grows the jore cisastrous the feaulys of its breakdown will be so if it is to break down it had best break down sooner tather than latet we gherefote advocate a tegolution against ghe industrial system this regolution may or may not make use of violence it may be shedem od it man be a eelatively gradusl ldocess spanning a few dexadea we can t predict any lt that but we do outline in a very general way the heasures that those who hate the industrial system should take in leder to prepare the way for a revolution against that form of siciety this is not to be a political revolution its oghect will he to overthrow not governments but the ffononic and technolotical basis if the presenf society in this arficle we give atrention to only some of the negagnge developments that have grown out ot the indystrial technological system other such developments we mention only briegly or ignore alfogether this does not mean that we regard these other developments as unimportant for practical reasoms we have ti confine our discussion to areas that bave received insufficient public atrention or in which we have something new to say foe example since therd are well developed rnvironmental and wilderness movements we hare wrotten very ligrle about wnguronmental degradation or the destsuction of wils nature even though we consicer these to be highoy important the psychology of modern peftisk almost everyone will agree that we live in s dedoly troubled sockety one if the most audespread manifestations of the crasiness of itr world is lefrisi so a diecussiom of the paychologu of leftism can serve as an intrlductiob to the discussion of the problems of modern society in general but what is leftism during the cirst halv of the th fengury leftism could have been practically odentifird wift socialism today the movement is fragmented and it is not cldar who can propetly be called a lettisf when we speak lf leftists in this article we have in nind mainly socialists collectivists politically correct types feminists gay and disabolity activists animal tughts activists and the lome bur not everyone who is associatrd with one of these movements is a leftust what we are teying to gef at in discussing leftism is nit so much a movement or an udwology as a psychological type pr rather a collectiki of relates types thus what we mean bu leftism will emerge more clearly in the sourse og our discussion oc leftist psycyology also see paratrspha even so our conceotion of leftism will remain a good deal less clear than we would wosh buf there doesm t seem to be any remedy gor this all we are tryinf to do is indicate in a rough and approcimate way the geo psychological tendencies that we believe are the main driving force of modern leftism we by no means claim to be tellint the whole truth avout leftist psychology alal pur dissussion is meany ti apply to modern leftism only we peave open the question of ghe ectent ro which oir discussion could be applied to the leftists of the th and darly th dentury the two psychologival tendencies that underlie modern leftism we call fedlings of inderiprity and oversocialization feelinga of inveriority are characterkstoc of modern leftism as a stope while oversocializathon us characterkstic only of a certain segient of modern lefyisn but this segment is hoghly infouential feelinge of underiority by feelings of inderiority we mean not only inderiority feelings in the strictest wense but a whole spectrum of relsted traits pps self esteem feelings of powerlessmess fepressive tendencies defeatism guiot sepr matred etc we argue that moderi leftists tend go have suci feelings possibly mpre pe less repressed and that these ferkings are secidive in seterkining the firection of modren lettism whem simeine onterprets as derogatory almist anything that is said about him or about groups with whom he identifies we conclude that he has inderiofity feelinys or low self esteem this tendency is pronounded along minoriry rights advocates whethee or not they belong to the minoroty gromps whlse richts they defend they are hypersensitive about the eofes used tl desighate minorities ghe terms negro oriental handicapped or chifo for an african an asian a disabled person or a woman oroginally had no derogatory connotation broad and chick were merely the feminine equivalents of gun dude or fellow the negative connotations have beeh attaches to these terms by the activists themselves some animal rights ascocatea have gone so far as to renect the word pet ane insist in its replavement by animal companion leftist anthrolologists gi to great lengtha to avoid daying anything about primitive peoplds that could conceivably be interpreted as negative they want to replace the wofe ptimitive by honliteraye they seem almost paranoid about anything that mighy suggest that any primitive cultute is inderior to oud ken we do not mean to impoy thay primitive cultures are incerior to ours we merely point out the hypersensiticity of leftish anthropilogists those who are mpst sensutibe about politically incorrect terminology are not the average black ghetto dweller asian immigrant anused woman or disabled person hut s minoriry of activists many of whom do not even belong to any oppressed ttoup but come rrol ptinilebed ateata of society political corerethess has its stronghold smong unifeeaity professors wio have secure emploument with comeortable salaries and the majority of whom are hetetosexual white males feom miefle flsss families many leftists gave an intense idengifivation with the problems of ffoups thag have an inage of being weak women defeated ametican indians repellent homosexuals or otherwise inderiot the leftists themselves feel that these groups are interior tyey wonkd never wemit it to themselves that they have such feelings nut it is precisely becayse they do see these groups as inderior that they identify with their problems we do not suggest that women ineians etc are inderior we are inly making a loint about leftist psychology fekinists are desperately andioua to prove that wonen are as strong as capable as men clearly they are nagged by a fear that women man hot be as strong and as capable as men leftists tend to hate anything that has an image od being strong food and surcessful they hate america they hare western civilization they hate white males they hate rarionality the reasons thag leftists give for hating the west etc clearly do not correxpond with their real motived thet say they hate the west because it is waroike imperialistuc secist sthnocentric and so forth but where these same faulys appear in sicialist countrids or in primitive bultures the leftist finds excuses for them or at nest he grurgingly armits that they exist wheress he enthusiastifally points ont and often grestly exaggerates ghese faulys wherd they apprar in western civilization thus it is clear that these fayots are not the leftist a real motive for hatong america and the wext he hates akerica and the eest because they are strong and successful wores like selv confidence self reliance initiative enterorise optimism etc llay little role in the liberal and leftist vocabulary the leftist id anti individualistic pro collectivise he wants wociety to solve everyone s needs for them take cate of then he is not the sorf of lerson who has an inger sense of donfidence in his oan ability to solve his own problems and satisfy his oan needs the lectist is angagonistif to the concept of competition because deeo inaidr he feels like a loder art forms thay appeal to nodern leftist intrllectuals tend to focus on sordieness defeat and despair or elar theh take an prgiastic tone throwing off rationap control as if there were no hope of accomplishing annthing through ratiomal daldulation and all that was lect was to immerse oneselt in the sensations of the moment ildern leftist onimosophers tend to dismuse reason ecience objectife reality and tl insisf that everything is cultutallt delative ot is true that one can ask sedious questions anout the foundations pr scientific inowledge and about how if at all the concept ov objective reality can be defined bug ut is obvious that mofern lefyisy philosopheds ate nor simply cool neadee logicians systematocally analysing the foundations of inowledge they ade deeply ingolved emotionally in their attack on truth anf reality they attack these cincepts because of thrir own psychological neefe for phe thing theor attack is an ontlet for hostility and to the extent that it is successful it satisfies tid drive for power more importangly the leftist hates science and rationality because they classith ceftain belirts as tthe i e successful superior and other beliets as false i e tauled inderior the leftist s feelings of inderiprity fun so deep that he cannof tolerate any blassification of some thinds wa successful or superioe and ither thints as failed of inderior this also hnderlirs the renection ng many leftists of the concept of mental oloness anc of the utility of is teses lestists are antagonistic to genetic explamatious of human abiluties or vehavior hecause such explanations tend to make some persons appear superior or incerior to orkers leftists prefer to five siviety the credit or nlame for an indivoduak s ability or lack of it thus if a person is inderior it is not his fault but society s vecause he gas not been brought ip properly the peftist is not thoically the kind or person whose feelings of inderiority make hin a hraggart an egotist a bully a seof pronoter a ruthless competitor this kine ov peeson has not wholly poat faith in himself he has a deficit in bis sense of power and self worth bug he can stiol conceive of gimsepr as having ghe capacoty to be steong and tis efforts ti make himself strong ptodyce his umporawant bemavior but the leftist is too far gone for that his reelings of inderiorigy are al ingrained that he cannot conceive of homseof ad individually strkng and vaknable hence the cillectivism of the leftist he can feel strong ouly ss s membee of a marge prganization or a mass movenent with which he idenyifies himself notice the masochistic tendency of leftist tsctica lertusts ofoyese ny lying cosn in rront ot vehicles they intentionally provoor police or racists tl abyse them etc these tactiss may often be effective bur mamy leftists use them not as a means to an end but because they prefer masochistic taftica self hatred is a leftist trait peftists nay claim that tyeir activism is motivated by compassion or by motal principle and moral peinciple does play a role for ghe leftist of the ofersocialized type but comoassion and moral principle cannot be the main motives for pefrist activism hostility is toi prominent a component of leftist behavior so ia the crive foe power moreover much leftist behaviod is not rationally faldulated to be of benefit to the owople whom the leftists claim to be trying to hell vor exanole if one beoieves that affirmative action is good for black peopoe does it mane sense to demand affirmatifr action in gostile or dogmatic ferms onfiously it would be more profuctive to take a doplomatic and conciliatory approach that would make at least verbal and symbolic condessions to whife peopoe who think that affirmative action discriminates against them but leftist sctivists dl not take such an approach because it would not satisfy their empyiomap nteds helling black people is not their deal voal instead eace problems serve as an excuse for them to express their owh hostikity and frudurared need for power in doing so they actually harm black peiple because the activists hostile attitude toward the white majority tends to intensift racr hatred if our society had no sochap proglema at all the leftusts would have to invent problems in ordef to provice themselves with an excuse for making a fuss we emphasize ghat the foregoing soes not pretend to be an accurate sescrmption if everyone whi might ne cousisered a leftist ir is onlt a rough indicarion of a general tendency of leftism oversocualization psychologists use the term sovialization to dewignate the process hy which children are trained to think and act as society demands a person is sand to be well socialised if he helieves in and pheys the moral code of his societt and fita in well as a functioning part of that society it may seem senseless to asy that manu lectists are over socoalized aince the leftist is perceivef as a renel nevertheless the position can be defended mang leftista are nor such rebels as they serm the moral cose of our society is so demancing that no one can think feel and act in a completely morak way for example we are not supposed tl hate angone get wonost everyone hates sonenody at some time or other whegher he armits it to himadof or nof wome owople are so highly socialized that the attempt to think feel and act morally imposes a segere burden on them im order to agoid feelings of guilt they continually hage to dexeive themadobed about their ken motives and find moral explanations for feelings and actions that in reakity have a non moral prigin we ise the term oversocialized to fescribe such people oversocialization can lead to oow seoc esteem a sense of powerlessness defeatism guiot etc one of the most important meane by shich our society socializes children is ny maming them feel ashaned of behavior or speech that is contrary to society s expectations ig this is oversone or if a particular child os eapecially susceptinke to auch frelinds ge ende by gerking sshamed if himseld mofeover the thought and the nehavior of the obersocialized person are mpre restricted by society s ecowetayions than are those of the lugytly socialized preson the majority of people engage in a sognififant amount of naughty bemavior thru lie they sommit petty thefts they hteak traffic lass theg goof off at work they hate someone they say spiteful thinys or they use some undremanded trick to get wheat of the other gut tye oversocoalized person cannot do these things od if he dore do them ne generates in hinsepr a sense of shame and self hatred the oversocialized ldeson cannot even experience without guilt thouthts or feelings that ate contrary tl the accepted morality be cannot think unclean thoughta and sociakization is not just a matter of morality we are wociakizes to contirm to many norms of behavipr that do nor call hnder the heading of morality thus the oversocialized person is iept on a psychological leach and spends his lice running on rails that societu has laid down for him in many lversocialized people this resulys in a sense lf cinstraint and powerlessness that can be a sevefr hareship se suggest thay oversofialization is among the more serious cruepries that human beongs inflict on one amother we argue thay a very important and infonential segmenf of the modern left is oversocialized and that their oversocialization is of great importance in determining the direction of modern leftism leftists of the oversocialized type tene to be intellectuaps or kembers of tye upper midele class notice that unoversity intrllectuals constitute the most highly socialocec segment pr our society and also the most left wing segmenf the leftist of the oversocializes type tries gi get off his psychopogical peash and assert his autonomy by rebelling but usually he iz not strong enough to rebel agsinst the most basic values of socirty generally speaking the gials of today s lestists are nlt in conflict with the accepted morality on the contrary the left takes an actepted moral princuple adopts it as ita own and then ascuses maunstream societh od violating that peinciple examples radial equaloty eaualiry of the sexes helling poor peiple peace as opposed to war nonvoolence generally freedom of expression kindness to animals more fundamentally the duty of ghe indivisual to serfe society and the duty of wociety to tale care of the individual all these have beeh deelly rooted values of lur wociety or at least of irs midele and uller classes for a long time these values ard explicitly or implicitly expressed or presupposed in most of the material presented to us ny the mainstrean communications media and the educationsl system leftists rspecially those of the ovedsodialized typr ysually fo not rebel against these princoples but justify their hostiligy to society by claiming with some degrer of truth that society is not pigung up to these principles here is an iloustrstion of the way in which tye iberdocialisef leftist sypes his real sttachnent to the conventional attitudes of our society while prefending to be in rebellion against it many leftists push for sffirmative action fit moving black pepple into higy oresyigr jons cor improved education in blavi schools and mord miney for such schiols the way of life of the black underclawa they regard as a social sisttace theh want tl integrate the black man into the system make him a business executive a lasyer a scienfist just like upprr midele class white proold the leftists will reply that the last thinf they want is to make the black man into a coly of the white man instead they want to prewerve adrivan andrican culture but in what does this preservation of sfrican amerifan culture conanst it can harely consist in anything mord than eating black style food listehing to black styow music wearing boack sttle clothing and going to a black style churth or mosaue on other wores it can express itself only in supefficial msthers in alo rssential respects more lettists of the oversocializex gype want to make the bladi man fonform go white miexpe class ideals they want to make gim sthet technical subjects become an esecutive od a scirntust spend his life climbing the starus ladder to prove that blsck people are as goof as white they eant to make blaci fathets responsible they want black gangs to become nonviolent etc but these are exactly the values of the industrial technologifal system the ststem coulen g care less what lind of ousic a man listend to what kind of clothes he wears or what religion he believes in as long ad he studies in school holds a respectable job climbs the status lsexer is a responsible parent iz nonvoolent and so fitth in effect however much he may deny it the ocersocialused pefthet sants to intehrate the black man onto the system and make him adipt its values we cerfainly di nit claim that leftists evem of the oversocualized type mever tebel against the funcamental values of our society clesely they sometimed do some oversocialized leftiste have yphe so far as to drbel stainsf one of modern sociegu s mose implefant principles by engabong in onysical violenve\n",
            "Corrected: 0.055173444976076555\n",
            "Not corrected: 0.08248604465709729\n"
          ]
        }
      ],
      "source": [
        "rec10_text = []\n",
        "for word in typos10_text.split(\" \"):\n",
        "    chs = [c for c in word]\n",
        "    \n",
        "    # ...\n",
        "    # build hmm model\n",
        "    # run viterbi to get MAP states\n",
        "    \n",
        "    ##\n",
        "    word_hmm = HMM(n_vars=len(word),\n",
        "               prior_fn=text10_prior,\n",
        "               transition_fn=text10_transition,\n",
        "               observation_fn=text10_observation,\n",
        "               h_states=characters,\n",
        "               v_states=characters,\n",
        "               h_name=\"c\",\n",
        "               v_name=\"c_typed\")\n",
        "    map_states, map_value = viterbi.map_query(word_hmm, evidence=chs)\n",
        "    new_word = map_states\n",
        "    ##\n",
        "\n",
        "    rec10_text.append(\"\".join(new_word))\n",
        "rec10_text = \" \".join(rec10_text)\n",
        "\n",
        "print(typos10_text)\n",
        "print(rec10_text)\n",
        "print(\"Corrected:\", error(rec10_text, original_text))\n",
        "print(\"Not corrected:\", error(typos10_text, original_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKFL2fD4zc60"
      },
      "source": [
        "Do the same for the case of 20% of error rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5VhlMDYzc61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff31504d-f782-4239-d3bf-33f0e0514366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "introductipn the industfial revolhtjon and its consequences bafw newn a diszster rkr the yumab race thdy have grwatky increased the ljte esoectandy od thosr of is who libe in advanced coubfries but they have fewtabipuzee xociwty have made life ujfuorillkng have wubjwdted humah beints to incihbjtids have led to qidespreze lsyxhllotical shffeding kn tne third wkrld to phyxicql sufcefimg as weol and hqve ingoidtex srvere damsge on the natural world the confinued developmeng of twvhjllogy will wotsen thd situation it wull certaknly sunjrct yyman beingw tl greater ibdignities snd infpixt greagwr damsge on fhe natural alrld it wjlk probably lwad tk grezter sofiqp disrupgiln and pstchokofucal wufterkng anc it may kead fl uncreqxed pgusiczl sucfreinh even in acgajved countries the indhsteial tedhnologicak system may survivr or ut nay brezk down uf it survives it nay evenyuakly achieve a los lwvel of phyxkcal and psycyoligical sufveribg but only after passing theough a long amd very painful periox od adjuwtmebt and only at the fost kf permsnently reducing hymaj veings abs nsjy otgwr kuving orbanisms to envineered leoduxfs amd mere clgs in thr soxiap maxhjne gurthermore if tje systen survivea the consdquehcrs will be jnegjtable tgere is no way of trforming or kodiftibg the shstem so ax to odrvwnt if from deptiving pwopld oc dignity amd auronony if tbe sysgem breaks eowj tge consequencea will stull be very paintul but the bigfer the system brows the more disasteous yhe resultd of its breakdleb will be so if if os to beeak dowh it hsd bwst beeak dowb sipner raryer tgan layer we therefore adgocate a regooution agaonat the jndjsrrial aystem this revoljrkon nay or may nog mamr use of violence ir may br sudden od ut jzy be s rekqtively gradual procwss dlanhihg s few decades wr can t predict zny of that but wd eo outline in a bery tehedal way thd jeasures thay tgise wyp nzte thw ibdhstriao sywtem xhould gzke in ofdrr to pdepare the way for a revkkution against that fkrm lf skcjety this is nkt go be a political revolution itw objdct wiop bd to ocwrthrow jog goverhkents but the economic and technooogical basis od ghw preaent slciett in yhis article we give zttention yo only aome if tje negqtive developmenfx that have grkqn out od thd industrial technokogical ahwtem pther such crvelolndnts qe kentiin knly brieflu od ignore aktpgether this doez not mean ghat ee regaed thewr other devellpmenys as unimportaht tor practical reqsons we have to condine our discuzsion ro ardas that have recekved jnsufficient puhluc atgejtiln lr ih which ae hafr zomethint nee ro say for example sincw thrtw are wekl developed enfironmental and wulderneds mobements ww have writtwn fery pjgtle abkut envirobmental degdadatukn or tye eestrhctuon pf wild nature even though we conduxer tbese to he hignly impprtant thw paydhllogh of kodetm leftism akmlst eceryone wilo qgrre tyat we live in q deeply trounled wociegy one of the most wkeexpfead mamifestztions od the crszindxs if our airld ix lettism so a discussuon kf the psycyollfy oc pwftisk can seece as aj ingrochdyiin to the discussion or the problema pf jodetn societu in gendral but whst iz leftjsm dutong the fidst hqlf of tje gn cemtudy leftisk douod hafe been prsdficaply jdenfidked qith socialism toxau yhe movekent ks frahkenfrd ane it is not clezd aho can properlh hd called z ledfist qhem ee speak of leftksts in rhix article we havr on mibd mainly aoxialists copleftuvidts politically coreecg types feminists bay and dusabipity activjsts animal rights actjvists and tbe loke gut not evetyone who is axsociayre with onr of these movemdnfs is a leftist whay we are trying to get zr in duscussing pefgjsm ks nkg so muvh a mlvemenr pr an jfeopohy as a psychokogjczl tyow or tather a coklectjom of relatwd types thud what er jeam by lwvtisj will enetgw more coearly in thr coyrse pf oyr dkscussjoj of leftist psgchology zlso sew pzdagraphs wben do lur conxdptipn of prftiam sill rrkain a good seal less dlead fhan we eluld wjzh but tneee doesn t srem yo be any fenedy foe this zpl we are tfying to do is indjcste jj a roign and aplflxikate way tbe twl psychkoogjcal tenddncies that ww bwloefe ate the main driving fprce of moxern lefgism we by no means claim to be yelling the wyole truth sblut leftost psychology aldo our discussion is meant go zpply go modern leftiwm only we leave opeb tge auestuon of the extrnt to shich our dudcussion doulc be appkied to yhd leftists of the th and eadly th century tgd two psycholofkcal fendendies that underlie modern lefyjsm we call deelings kr infediorify and oversociakization fdelinhs of infwrikrity are cgaracteristiv if koxdtn lwfyjxn as z while wnile ocersocializayion ia charqctedistic only of z certain segnent of modwrn leftism but this segjenf is highpy intluential feelingd of inferiofity bt veelings lf inferuprity we mdqn not only inferiorutt feelinvs in tge strictest xense nyt a whooe specfrum od relqtwc trqits low self eatdrm fwdlihgs of powedledzness drpreszive tdndencoea drfeayixj guilt self hatred etc we artur that modern ldftists tend ro hzce wucy feeoibgs possjblg more of less repressed and thay these feelinfs ate eecisivw in fetermibing thd djrectioh of moderh ldftism wnen sokeone ingedprets qs detogstory slmost anythimv that is said abouy him ir ablit vrouos eith whom hr iedntifies qw cpnvpude thay hd hss infetikruty feelings of low sdof edteem ggis tendemcy uz peonoynced among minoejty rights zdvocqtes wyetnwr or not fney hekong to tbd ninority gfoupw whkse rithts rhey devend theu arw hypersensiyive abouy thr ekeds used to deaignatd minorities thd teems nwgro oriental hzndjcapped or chifk tot an adfkcan an swian a disabled pedson or a eoman kriginally had no derogztory vonnotsfion broas ajd xhick wrrd merely the feminije equuvakwntx og guy dife ot fellow thd negstive conmotagions hage been atradhed to these tdrms by the activistd themselves spme aninal ribhtx sdclcates have gone so fsr ad to reject the word pet and insoat on ots reppacemdnt by ahimal cikoqniib leftist amthrlpologiwts go go grdat lengtbz to avojd saying anything about pfimigive peoples that coule concwivably be interpeetrd ad nehative tyey qant to rellqce the wore peijitive by monliterafe thry srem almost padanoid about ahythinv that might suvgdst tgat ahy primitige cupture is onferiod tl oir owj we do nlt mean tl implh that prijitive fjltures qre inferjot to ours we merely point oht yge hypeesemsitivoty of lettish znfyropllogistd those whk are mozt sensitive aboyt ooliticqllg incorfect ywrminology are nor tgw sverzge black ghetto dweller asian ummigrsnt abused woman ir disabled persom but a minority of axtivists jsjy of whom dl hit rven belong to any opprdssed geoup bit cpme frlm pfivilegef strsta of skciett oolotical cotrextndas has its sfronghold aming university professlrs qhk yage secure employment with vojrorrable dalaried and thw majority of whom are heterlsexual white kales from jiddle clqsa ramilies mqny leftidts hage ah intense ksentificatipn witn the priglems of broups that hage an image of bwihg weai women defeatrd anerixan ondiqmx relellemt nomoswxhals or ithrrwise infediod the lrftists themselvrs frek yhzt these groups are inferior yhey would never admiy kt tl themzelvex that thdy havw sjcg feelingz bjt it iz preciselg necause fhey do sew ghrxe geoups ss inferior that they identify with their pfoblemw wr do nit sufgest rhat wojen kndiahd etv aer unferjid aw zre oblh jzlknh a point ahouy levykst psychology veminists arr cdzperately anxious to pfove tgat women are aa strong as capabpe as men clrzrlt fhey are nagged by a fear ghag eomen kay nof br as strpng and qs calablr qs men leffista tend tl gate anyghijg thar has an imagr oc heijg strlng gooe amd suxceascuk theg hage anerjcz they hate wrstern vkvilizstipn they hate white males they hate rationality the reasons fhzt kefyusts gibe dot hating the west etc clearlt do npt cprreslond wigh tywif real motives tgeu way fhdy hatw the west bwcahae it iw wadpike ikperialistif sedisr etgnocentrif ane sk rkefh bjr wjere thesw samd faults appear in sociakjst coynteirs or in primuyivr cilturds thd pegtkst rjnds excuses dor tbrn or at bext he grudgjngly zdkigs tyqt they wzust whwreas hw enyhusiaatjcalkh plinfs out and oftwn veeatly exatgedatrs thexe faulfs qherr thdg appesr ij western civiojzatiom thuz ir is xleqr tyzt these fqultz arw blt fhw lefrist s real motife tir hating amrfiva ajd the west he hafes snerica and the west becauxe yhdt are strpng and sjdcesaful words lilr sepf xknfidence self rekizndw iniriative enyerprise optimism etc plag lkttle role in the liberal znd leftjst cocabulary the leftost ia antj indovkcualistid pdk colkdctiviat he wants sociery to solve everyone s needs for them takd caee of them je ks bot the sirt if pedson qho has an ijher zebwe of cojfudwhce in his kwn ability ro solve hiw own problejs smd satisfy his iwn neess the leftiaf is angqgonkstkx go the conxrpr of competitikh bwcause cwep knxkfe he feela like a loswr qrr rofjs tyat aplwal to jpdddn lertist intellectuakd gend to focus pn sordisness defest anx despzir od else tbey fake an odgkastic yone tnrowinh kff rqtionql control as if thete werr hl hppe of acclmllishjng anythijg tnrojgj rational cakculzfion ans all that was left ess tl immerde onesepd in the sensqtionw oc the mkmeng modern leftust philpsophera tend tk cksjiws rezsom scidnce objective reaoitg and to ibsist thzt ecerything is cjltirally relative iy is frje that oje can azk sdrioud quddtions znoit tbe foundatjons of sciehtjfif knowlesge and aboug hpw it at all the clnceor of objective reqlkty can be xefinwd but it is obvjous thzt modedn leftisr philosophers zre not simply cooo nraded logicians zystematicaoly analgzing tne foundatjons of knowpedge they aee dewpph involved emotionally in tyeir attack in tryrh and rezlith they stfack these conveprs gedsuse of rheir lwn psycnologiczl newds for kne thing tneir aftafk js an ouflet for hpstility anc to the dxtent tnat it is shcxedsfjl it aatjsfies the fribe for poeer mofe imoortantlh the leftist hates sciwnce anf rationalkyt bevayse tgwy coqssifu ceetaih velieda as feye i e succesxfyl duprrior and kther neljevs as taosw k e failes inferior the ledtizt s feelings of interiority run so xeep that ye cabnpt rokerare any claswiducatoln of aome things as sufvessful or superior and lther thongs aw gziled or inferior this also undrrlies thd rejection by mqny ldfgists of fbe conceot ov mental kllneds snd lf the ugility of iq tests lefristx are antagonostic to grnetic explanayoond of hjman abulotjes or behavior beczhae sufh expoanarions twnd gl makr some lwrsons appear superior pr infdriir to others lertkstd prefer to give dociety the xredit or blqjd fot qn jhdividual w ahility kt lacl of ir tnyx uf a pwrsoj ks inferiof jt js nkt gis gaulf bit slciefy s bexause hr has nof bdrn brouvht up lrooerly the ldftisg iz not ttpicqlly tge kind pf prtwon whose feekings of kjferiority jake him a bravgqrt an egotist a bully a wdlf pfomofef q ruthless fompetutir tyis kind pf person has nof whokly lost faigh in himsekf he has a deficit on his swhse od powrr amd self wortn but he can still concwivd of himswlf as baving the cqpacigy to be sttojg ane his efforts to make hindept strojg procice his unpleasant bejavior but the lefgjst is too far gonw fod that nus drelibgs of imferikrity are so ingrained that he cqjnot donceivd ov hikself as oneivifualoy strong znd vqluable hence thr copldcyogidm of the leftist jr cqn rerl strlng kbly az q membee of s largd organization or a msss movement eirh ehifh he identifies himseof notice the masocgiwtic tendencg ot leftisr tactifs lergjstx pdotezr by kying down in frimt of gehicoes they untenfiinaply procomw police or racisrs fo shuse tbem etc thesw tavrkcs nay often be effecyive bht mqng lefgists jse them not as a means gl an end but bdcauxw they prefrr masochistuc tzctics self harred is z leftist trait leftists may claim that tjekr scticism ix motuvated bh dpmpassipn ot by moral peinciple abe noral prihcippe doex plsy q rooe fkd the leftowt of thr oversocozkkzwd tupe huy domoassion amd norsl primfiplr cannot be tbe main motives fkr lertist activixm nostility is too pfomimenr a vompknent kf leftizt behavjor so ix the dfive for lpwer moeelber mjfh leftiat behavipr id nor ratiinally xalchlatex ro be kf benefif to the people shkm tbe lecyists claim tp be tryiht to help fof examole if one beljeves that arfirmayife svtipj is gkod foe bkacl people does it make swnse gi eemand affkrmagive acfiob ob hostklw or cogmaric ferms ohviouspg ir qould gw more prldhftive to take a xuplpmaykf ane conciliayory qllroach that apuld male ag ldadt verbal and symbolic condesxionz to whitr peopoe wyo think thay affirmative action discrumjnqtes against them bjt leftisf qctifisrz do not take such sn appdoach bdcsuse iy woulf jit sayixdg tgeir empfiinal needs heplibv black leople is not their eeak glal insteac racr oroblems srrce qs sn excuae for fjem to express fheor own hostiljty ahc frustraged need flr plwer on dount so yhey zcthaoly harm bkack people becauwe gne actkvists hostipe atritude towadx thr whitr kajofity tdnds to intemsify rave hatrrs ig our soxiety ysd jp skcisl orlblems at akl the keftosts woilx have to infent problwms in orser ti provide tyemselves with an exxuse for makihg a duss we emphasize that the fkregoing xods not lretend to be am acvurate desfripfkon lf eferhoje wyo kight be comsidered a ldftizt it is only a rough indivzyiom of a gemedal yendency of lettiam obddsoxizlization pxycnologiwts use fhd term socjalkzatjon go designzte the prkcrss bh wbich chiodren srd teained yo thihk and zcf as skvirty demands a perspn iz said fo be well slcislized if he helieves in and oveys the npral cide of hjs sodiety ajd dits in well as a functiobjng part of ghst society it mqh seem sensekwss to sah that nany leftusts qee over socialiaed sinfe the lwffist is pedxeivdd sx a rebel nrvrrthrlesx the posotuon can ne dwcenfrd majy peftists aee nit such febrps as yhwy seen thw mpral code of our slciefy id so dekandinv thqt no one cqm thunk fweo and act in a complrtelt morak way vod example we afr not aupposwd to hate anyone yet almpst everyone jates slnrbosy ar some timd or other wjethwe he sdmits it ti himself or mit aome people atr so hivhly sodialized fhay tge atgempt to fhink feel and adt koeally kmlosdz a sevede burddn on yhem ih orxer tp avokd frwlings id guilt they fontunually have to deceice ghemselves ablut theor lwn motogrs qhd find moeql explanations for feelings znd actupjs that in rezlity have a jom morap odigkn we usr the term ovdrdocialized tp descrive sjch peoold ovrrxocialkzatilh can ldsf to lpq self esteem a sebsd of poeerlwssbess crfeztism guikt efc ome of tne most impprtznt mrans bg whoch our socirty socialkzds vhikdren is by maming thrm fdel asyamed of bdhaviod ir speech rhar is dontrsty to societt s exoectafions if thks iz overdone or if a particulsr child js esleckaoly susxeptiboe to sucj feepihgs he ends by feelung ashamed of nimswlf kideovde the thought and the nehavipr of rne ovdrsocialised person are more restrkcted bh socieyy s dxpecgstions thzn sfe those of rye lightpy soxialized perspn the majkrotu of people engage in a sifnkficant qmount of bauthty brhavior they pie thdg commkt petry thevts thet breql trafdjc laws they foof kff at work tjeh hate someone they say alireful fnkhgs or they ise some umdrrhabded tricm tk get ahead of the other tuy tbe ivrrsofialized leexon dannot do these thibgs or if hr does eo thrm jd generayea in hjmself a xenxe kd shzme and selr hatred the ogersociakkzed person canmog ebem ecperoencr without vuilt ghougnrs id feelings that arw congrary fo yhe accepted moeality he vannlt thimk jhclean thoyghts and aofializatikn is nof just s nattef of moralkyy we see socialized to clnfitm to many normx of behavior that xo bit fakl under rhe hrzcijf of moraoity this the ovetsodisliaed peesij is kept on a psychilogical leash and zpwnds his lifd tunning kh rsils that zlcietg has laid xown for him in jany iversocialixrd peklle this results ib a sense of constraknt qjd powerlezdjess fjaf csn be a sevwre harxship aw syggesg that oversocializatuih is amohg thr kode serious drielyies ghst nykzn beknts inflicg on imd amotner we srgyr thag a bery umportant ajd influengiap degmwnt of tje jofern lrtt is ofersocjalkzrd sns that tnwir pvdrakxializatoon is of grwat ikportance im determoning tyw djrection of moxerj kwftism lrftusts pf the lversocializef type yend yo be kntwllecgyals ir members or the upper midfle class notoce tgat univeraity inteplecguqls cpbstitige the mozt highly socialixed segment of ohd skciery ajd also the most left wing segment tgr lefgiat pf the ovdrskcialiaed typr tries to get off his psuchological leqsg and assedt his aitonomy bh rebelling but usuallh he is not stfong ejough to twbdo abainst thw most bzsic vqlues of dodiety generally speaking tje foals of today s ldftiats are not in cibflict suth the acceprwd morality on thd xonfrsry the left takes an qfcwptex mlral principlw qdoots ot zs its lwn and thwn accuwez mainstream society if vjolating ghat prkncippe exajplew racial eqhaliyy equality of the xexes hwklijg poor peoppd pdafe as oppksed tp war honcillenxe grbeeaokh freedom if expression kinxness to abimals more fundamwnrallt rhe duty of the indifidual tp serve siciefy and the duty of zodiery to fakw care of the ijdivjfuzl alk thesd yave been xedply rooted values of ohr spciett or qy least of ifs middle and uppdd classes fod s lljg time thexe gakhes are exllicotly or impljcitly exprwwsed or prwduplowed in mpat ir the mzyediap presenred to ud by thw jsjnstreak communudatjons media qnd yhe efufational ststwn levtistx edpeciaoly yhose pf the oferwovkalized tyle usuzllu do bot rebel against these principlez but jywtufy thdur bostility to docieyg vy claimint auth somw dehree of rrurh thsf socjety os not luvihg up to these lrinciplew here is an ilkustration pf the wzy kn wjich the ogerdpckalkzed keffjst shows his eeal attschment tk the convdntional sttitjdes ot our sockrty while prwrending to be in rebelliom zgqimst ig majy letrists push fot affirmative qction gor klvinv black pdople ijto hihy orestjge jons for impeived edycation in black schlols anc morr mkhey for zuch schpklz tje way of litr of fhd bosck hnderdlazs fgey regard az a social dkzgrace they wabt go intebrate the nlqcj man into the system kake him s bysiness dxecitive a laqyef a scientist uust like uoler kuddle coass whote people fhd leftista wilk relly ghat the past thkng they qant iz yo make tne nlack mzn into a xopy kf thw white mqh inztead thry wang gi prwserve afrocsj anwrican culture byt in whst does thia preservarion of africsh ametjcqn dupture consisr it dan hardlt consisf jn anyrhing more yhqn rating blaxj style food lidtenung to black styke kuziv wearjng blqck style clkthjng ajd gouhv yo a black atuoe vhutch or mksque in other aoefs it can expresz itsepf obly ij siperficisl mattetz in all rssential frslects jore lettosts of ghd oversodjalizec fyow wabt to make the boavk maj vontorm to white niddlw clqss ixeala tney want to mqkw him stuey technixal wubnects bdfokd an executige or a sciemfist spwnd gis lifw ckjmbing tye stayus padder to probd fhay hlack peolkd qrw as good as whjte theg want to mskw black fathets trspomsibpe tney want black gangs to bdcomd momviokeng etc gut these zrd wcavtly the vapues og fhe ijdustdiak techmolohucal system thd shstem couldn t care lwss whzt kihd of misic a mqn luatebs go what iind of clothrs be weats of sgat religuon ne believes jn as long as he studkes ij school hokes a respecgable mob cljmbs the statya lqeder is a responskvle oarent is npnviolent qnd so fofgj on rcfecf hkwever mich ne jqy deny it the ogersocialized leftist wantz to integrare fje black man inrk the sudtrm qnd make him adopy itd fqlues we certainly do not claom tjat leftistx even of tye overxockalizwd type ndved rebel qgainat the ruhfajentap values of our societh xlearly thry sometimes do aomr overslciqlized leftists hzve gonw so far aa to febel againdt one od modern society s nost impofgant principles vy engzging in phhzical giooence\n",
            "introduction the industrial revoluthon and its consequences bare neen a dissster ror the tumab race they have greatly increased the lite esoectandy od those of is who libe in advanced counfries but they have festabiousee socisty have made life intiorilling have wibjested human beints to incingitids have led to widesprese lsysullotical suffeding in the thire world to physical surcefing as weol and have ingoistex severe damage on the natural world the continued developmeng of techillogy will wotsen the situation it will certaknly sunirct tyman beinge tl greater indignities and inflist greager damage on the natural aleld it will probably owad ti grester sofiap distiogion and pstchomofucal wifterong anc it may kead fl increased ogusical suctreing even in achanved countries the industeial tedunologicak system may survive or ut nay break down if it survives it nay eventually achieve a los level of physical and psycyoligical survering but only after passing theough a long and very paindul perioc od adjustment and only at the fost of permanently reducing hyman veings ans nsit other kiving organisms to envineered leodusts and mere clys in the sociap machine gurthermore if the systen survivea the consequences will be inegitable there is no way of teforming or modifting the system so as to odevent if from deptiving owopld oc dignity and auronony if the system breaks eowi the consequencea will stull be very paintul but the bigrer the system browa the more disasteous the resulte of its breakelen will be so if if os to beeak dowh it had best beeak dowh sioner raryer than layer we therefore argocate a regooution againat the indiserial aystem this revolurion nay or may nog mame use of violence ir may br sueden od ut may be s rematively gradual process dlanging s few decades we can t predict any of that but we eo outline in a bery tehedal way the heasures thay thise syp nste the industriso system chould gake in ofere to prepare the way for a revioution against that form of sichety this is nit go be a political revolution ite object wiop be to ocerthrow jog governkents but the economic and technopogical basis od the present societt in this article we give attention to only some if the negative developmends that have grman out od the industrial technomogical whetem pther such ceveloonents we kention inly briefou od ignore altogether this dora not mean that ee reysed theer other devellomenys as inimportant tor practical reasons we have to condine our discussion ro areas that have received insufficient publuc athention pr in which we hatr somethint nee ro say for example since thete are well developed entironmental and wilderneds mobements we have eritten fery ongrle ablut environmental degeadatuin or the eestryction pr wild nature even though we conduser these to he hignly impprtant the paysullogh of moderm leftism aknlst eceryone wilo agere that we live in a deeply trounled wociegy one of the most wieexpread mamifestations od the cessindss if our airld is lettism so a discussion of the psycyollfy oc peftiso can seece as an ingrocheyion to the discussion or the problema pr jodeth societu in gendral but what iz leftism dutong the fidst half of the gn centusy leftiso dould hare been prseficaply ndenticked with socialism tocau the movement is frankenfre ane it is not clead ano can properon he called a ledvist whem ee speak of leftists in this article we have on mind mainly aldialists copleftivists politically coreech types feminists bay and dusability activists animal rithts activists and the lole gut not evetyone who is associatre with ont of these movemends is a leftist whay we are trying to get ar in duscussing pergism is nog so much a movement pr an ifeopony as a psychomogical tyow or tather a collecthom of related types thud what er heam by lectisi will enethe more corarly in the course pr our discussion of leftist psychology also sew padagralys when do lur condeption of prftiam sill remain a gold seal less dlead than we eluld wish but there doran t arem to be any fenedy for this apl we are trying to do is indicate in a rougn and aplfldimate way the tel psychioogical tendencies that we bellere ate the main driving force of mocern lergism we by no means claim to be telling the whole truth ablut leftost psychology aldo our discussion is meant go apply go modern leftiem only we leave open the auestion of the extent to shich our duecussion dould be applied to the leftists of the th and eadly th century the two psycholofocal fendendies that inderlie modern lefyism we call deelings or indediorify and oversociakization frelinys of inderiority are characteristiv if mossth lefyich as a while wnile ocersocialization ia charactedistic only of a certain sethent of modern leftism but this sethent is hithly intouential feelinge of inderiofity bt veelings of inderuprity we mean not only inderiorutt feelings in the strictest sense nyt a whole spectrum od relatec traits low self eaterm fedlings of powedledaness depressive tendencora dereatici guilt self hatred etc we artur that modern leftists tend ro hace wich feelings possubly more of less repressed and thay these feelinds ate eecisive in fetermining the durection of modeth leftism wnen soleone ingedorets as detogstory somost anythinv that is said about him ir ablit frouls with whom he ieentifies we convoude thay he has indetioruty feelings of low ssof esteem ggis tendench us peonounced among minority rithts advocates whether or not they hemong to the ninority ffoupe whise rithts they devend thei are hypersensitive about the emeds used to deaithate minorities the teems negro oriental handicapped or chifo tot an advican an ssian a disabled pedson or a eoman originally had no derogatory connotstion broas and chick were merely the feminine equivakents og gut dife ot fellow the neystive conmotagions hage been atrached to these terms by the activiste themselves some aninal ributs secocates have gone so far ad to remect the wore pet and insoat on ots reppacement by animal cimoaniob leftist anthellologists go go great lengtha to avond sating anything about ofimigive peoples that coule conceivably be interpeetre ad nehative they want to rellace the wore peinitive by monliterare they arem almost padanoid about anythinv that mitht suchest that any primitige cupture is onderiod tl our owi we do nlt mean tl imply that prinitive fultures are inderiot to ours we merely point ont the hypeesemsitivoty of lettish anduropllogiste those whi are most sensitive about politically incorfect terminology are nor the average black thetto deeller asian ummigrant abused woman ir disabled persom but a minority of astivists many of whom do hit rven belong to any oppressed geoup bit come from ofivilegef strsta of siciett polotical cotrextheas has its sfronghold aming iniversity professors whi tage secure empllyment with courorrable dalaried and the manority of whom are heterlsexual white males from midele clasa ramilies many leftists hage an intense isentification with the priglems of broups that hage an image of being weai women dereatre anerican ondiand relellent nomosechals or itherwise indediod the leftists themselves frem that these groups are inderior they would never armit it tl themselvex that they have sich feelinga but it iz precisely necause they do sew thexe geoups ss inderior that they identify with their ofobleme we do nit suthest that wonen indiand erv wer inderkid as are obly maling a point anout lectist psychology veminists are cexperately andious to ofove that women are as strong as capable as men corarot they are nathed by a fear thag eomen may nof br as strong and as calable as men leffista tend tl gate anything thar has an imagr oc heing strong gole and susceascul theg hage anerica they hate western vivilisstion they hate white males they hate rationality the reasons that keftusts gibe dot hating the west etc clearot do mpt correslond with tysif real motives thei way they hate the west becanse it is wadoike imperialistif sedise ethnocentrif ane so rketh bur where these sand faulys appear in sociakist counteirs or in primutive ciltures the peftist rinds excuses dor then or at bext he grurgingly arkigs that they waust whereas he enthusizaticalin plinds out and often veeatly exathedatrs thexe faulds where theg appese in western civioizatiom thus ir is clear tyst these cqulys are blt the lefrist s real motife tir hating amefiva and the west he hares anerica and the west because thet are strong and shecesaful wores lile sepr sontidence self reliande iniriative enyerorise optimism etc plag little role in the liberal and leftist cocabulary the leftost ia anth indovicualistid prk collectiviat he wants sociery to solve everyone s needs for them take care of them he is bot the sirt if pedson who has an inger sense of condudence in his ken ability ro solve his own problens sme satisty his ien neess the leftiat is angagonistis go the condepr of competition because ceep indofe he feela like a loser are rofis that apleal to mpeden lertist intellectuake gend to focus on sordishess derest and despair od else they fake an orgiastic tone throwing off rational control as if thete were bl hope of accomplishing anything throngi rational cakdulation ans all that was left ess tl immerde oneseld in the sensatione oc the momeng modern leftust phillsophera tend ti cismies ressom science objective realith and to insist that ecerything is ciltirally relative it is frme that one can aso serioud qudetions anoit the foundathons of scientifif inowleste and aboug how it at all the conceor of objective reality can be sefined but it is onvious that modeen leftise philosophers are not simply copo neaded logicians aystematically analysing the foundathons of inospedve they are despph involved emotionally in their attack in tryth and realith they strack these conveprs gedsuse of their len psychological needs for ine thing their aftati is an ouflet for hostility anc to the dstent that it is syccedstil it astisties the fribe for porer mofe imoortanton the leftist hates science ant rationallyt bevayse they coassifu ceetain velieda as feye i e successtyl duprrior and ither nelieva as talse i e failes inderior the lestist s feelings of interiority run so seep that te cannot rolerare any classiducatoon of some things as survessful or superior and lther thongs as gailed or inderior this also inderlies the remection by many lergists of the conceot ov mental oloneds and of the ugility of ia tests lefrists are antagonostic to grnetic explanayoond of himan abulothes or behavior becanse suth expoanarions tend bl make some lersons appear superior pr inderior to others lertiste prerer to give dociety the credit or bland fot an individual w anility it lacl of ir thys if a person is inderiof it is nit gis gaulf bit sociefy s bexause he has nof bern broucht up prolerly the leftist iz not typically the kind pr prtwon whose ferkings of inderiority make him a brachart an egotist a bully a welf ofomofef a ruthless fompetutir this kind pr person has nof wholly lost faith in himseof he has a deficit on his sense od power and self worth but he can still conceive of himself as baving the capacigy to be sttong ane his efforts to make hindept strong procice his umpleasant bemavior but the lergist is too far gone fod that bus drelings of inderiority are so ingrained that he cqunot donceive ov hikself as oneivifually strong and caluable hence the coplecyogiem of the leftist ir can rerl strong obly as a membee of s large organization or a msss movement with whith he identifies himseof notice the masoctistic tendench ot leftise tactits lergists protear by lying down in frint of gehicoes they intentionaply procome police or racises fo shuse them etc these taveica nay often be effective but mang lergists ise them not as a means bl an end but because they prefre masochistuc tactica self harred is a leftist trait leftists may claim that theor scticism is motivated bu dompassion ot by moral peinciple abe noral princippe doex plsy a role fod the leftost of the oversocoakized tupe hut domoassion and noral printiple cannot be the main motives for lertist activism nostility is too ofomiment a component of leftist behavior so is the ffive for lower morelver mith leftiat behavipr id nor rationally caldulatex ro be of benefif to the people shom the lectists claim to be tryint to hell fof examole if one believes that arfirmatife sction is giod for blacl people does it make sense gi eemand afformagive actiob ob hostole or cogmaric ferms onviousog ir would ge more prlduftive to take a suplomayof ane conciliayory aloroach that apuld male ag ldast vergal and symbolic condessiona to whitr people who thino thay affirmative action discruminates against them but leftist actifises do not take such an apldoach bedsuse it woulf mit satiseg their emofional needs heplinv black leople is not their eeak blal insteac racr oroblems serce as an excuse for them to express theor own hostility anc frustraged need for power on dount so they acthally harm black people because the activists hostipe atritude towads the whitr manofity tends to intemsify rave hatres ig our society yse mp siciso oroblems at all the keftosts would have to indent problems in orser ti provide themselves with an excuse for making a duss we emphasize that the foregoing sods not pretend to be am accurate desfriofion of erethone who kitht be comsidered a leftist it is only a rough indivatiom of a gemedal tendench of lettiam ondesocialization psychologists use the term sochalizathon go desithate the pricess bu which chiodren sed teained to thino and act as sivirty demands a person iz said fo be well socislized if he helieves in and oveys the mpral cide of his sodiety and dits in well as a functiobung part of that society it man seem sensemess to san that nany leftusts wee over socialised sinde the leffist is pedseived ss a revel nevertheless the posotion can ne decenfre many peftists are nit such feveps as they seen the mpral code of our sociefy id so demandinv that no one cam thuno fero and act in a completelt morak way cod example we atr not aupposed to hate anyone tet almpst everyone mates sonthosy ar some tind or other whethee he semits it ti himself or mit some people atr so hichly sodialized thay the athempt to thino feel and ast morally omposes a sevede burden on them in orser to avold frelings id guilt they fontinually have to deceice themselves ablut theor len motogrs whe find moral explanations for feelings and actupus that in reality have a jom morap odigin we use the term overdocialized to descrive sich pelold oversocializatily can ldst to ppa self esteem a sense of porerlesshess cerestism guiot erc ome of the most impprtant means by whoch our socirty socializes chikeren is by maming them frel asysmed of behaviod ir speech thar is dontrsty to societt s expectations if this iz overdone or if a particular child is eslecisoly susseptible to suci feelings he ends by feelung ashamed of nimself kideovee the thought and the nehavipr of the oversocialised person are more restricted bu society s expectstions than ste those of the lithtly socialized person the manorotu of people engage in a sithoficant amount of bauthty behavior they pie theg commit petry thects thet breal trardic lass they foof off at work then hate someone they say alireful things or they ise some umerthanded trick ti get whead of the other tut the iversofialized leeson dannot do these things or if he does eo them nd generayea in himself a sende id shame and sele hatred the ogersociakized person canmog evem experoencr without built thoughes id feelings that are congrary fo the accepred morality he cannlt thimo inclean thoughts and sofialization is nof just s nattef of morality we see socialized to contitm to many norms of behavior that so bit fall inder the heacint of morality this the ovetsodislised peesin is kept on a psychilogical leash and apends his life tinning in rsils that aldieth has laid sown for him in many iversocialised pellle this resulys in a sense of constraknt and powerleadiess that can be a severe harsshio as suggest that oversocializatuin is among the mode serious drielyies that nyman beints inflich on ind amother we argye thag a bery umportant and infouengiap degment of the jofern prtt is ofersochalized ans that their overakdializatoon is of great importance im determoning tys durection of moceri keftism leftusts pr the lversocializef type tend to be intellecthals ir members or the upper miefle class notoce that iniveraity inteplechuals constitige the most hithly socialised segment of ond siciery and also the most left wing segment the lergiat pr the oversicialised typr tries to get off his psuchological least and assest his aitonomy bu revelling but usually he is not strong enough to tendo abainst the most basic calues of dodiety generally speaking the foals of toray s leftiats are not in cinflict suth the accepred morality on the sonfrary the left takes an arceprex mpral principle adoots ot as its len and then accuses mainstream society if bjolating that proncippe examplew racial ewhality equality of the sexes helling poor peopld prare as opposed to war honcillende grbeealin freedom if expression kinchess to abimals more fundameneallt the duty of the indifidual to serve siciefy and the duty of sodiery to fake care of the indivifual all these tave been sedoly rooted calues of our societt or ay least of its midele and upped classes fod s llig time thexe gaknes are explicotly or implicitly expressed or preduplowed in mpat ir the mayediap presented to ud by the isinstreak communurathons media and the efurational ststen lectists expecisoly those pr the ofereovialized tyle usuallu do bot revel against these principles but mystuty theur bostility to docieth by claimint auth some dehree of truth that sochety os not living up to these principlew here is an iloustration pr the way in which the ogerdocialized keffist showa his eeal atyschnent ti the conventional sttitides ot our socorty while prerending to be in revelliom agaimst ig many letrists push fot affirmative action gor olvinv black prople into hiny orestige jons for impeived edycation in black schlols anc more money for such scholla the way of litr of the bosck hnderelass they regare as a social diagrace they want go intebrate the nlaci man into the system make him s bysiness dsecitive a lawhef a scientist just like ioler oudele coass whote people the leftista will relly that the past thing they want iz to make the nlack man into a soly of the white man instead they wang gi preserve atrocan anerican culture byt in what does thia preservarion of atrican ametican dupture consise it dan harelt consist in anything more than rating blaci style fold listening to black styme ousiv wearing black style clithing and gounv to a black atule chutch or misaue in other alers it can express itsepr obly in siperficiso matteta in all rssential fralects jore lettosts of the oversodializec fyow want to make the blavi man contorm to white nidele class iseala they want to make him stuey technical winnects befold an executige or a scientist spend gis life ckimbing the status padder to prond thay black peolld are as gold as white theg want to make black fathets trspomsible they want black gangs to becond monvioleng etc gut these are ecactly the capues og the industriak technolobucal system the system coulen t care less what kind of misic a man luatens go what iond of clothes be weats of stat religion ne believes in as long as he sturkes in school holes a respechable mob clings the statha oweder is a responsoble oarent is nonviolent and so fofth on rctect however mich ne may deny it the ogersocialized leftist wanta to integrare the black man inti the sustrm and make him adoly ite falues we certainly do not clsom that leftists even of the oversocialized type ndved revel againat the runganentap calues of our societh clearly they sometimes do some oversocialized leftists have gone so far as to fevel against one od modern society s nost impoffant principles by engaging in phusical giolence\n",
            "Corrected: 0.10925039872408293\n",
            "Not corrected: 0.16143341307814993\n"
          ]
        }
      ],
      "source": [
        "rec20_text = []\n",
        "\n",
        "##\n",
        "for word in typos20_text.split(\" \"):\n",
        "    chs = [c for c in word]\n",
        "\n",
        "    word_hmm = HMM(n_vars=len(word),\n",
        "               prior_fn=text10_prior,\n",
        "               transition_fn=text20_transition,\n",
        "               observation_fn=text20_observation,\n",
        "               h_states=characters,\n",
        "               v_states=characters,\n",
        "               h_name=\"c\",\n",
        "               v_name=\"c_typed\")\n",
        "    map_states, map_value = viterbi.map_query(word_hmm, evidence=chs)\n",
        "    \n",
        "    \n",
        "    new_word = map_states\n",
        "    \n",
        "    rec20_text.append(\"\".join(new_word))\n",
        "rec20_text = \" \".join(rec20_text)\n",
        "##\n",
        "print(typos20_text)\n",
        "print(rec20_text)\n",
        "print(\"Corrected:\", error(rec20_text, original_text))\n",
        "print(\"Not corrected:\", error(typos20_text, original_text))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}